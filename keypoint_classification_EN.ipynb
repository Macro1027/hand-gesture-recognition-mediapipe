{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "igMyGnjE9hEp"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.7.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from scikit-learn) (1.16.0)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.7.1-cp311-cp311-macosx_12_0_arm64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
            "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
            "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
            "Successfully installed joblib-1.5.1 scikit-learn-1.7.1 threadpoolctl-3.6.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2HDvhIu9hEr"
      },
      "source": [
        "# Specify each path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9NvZP2Zn9hEy"
      },
      "outputs": [],
      "source": [
        "dataset = 'model/keypoint_classifier/keypoint.csv'\n",
        "model_save_path = 'model/keypoint_classifier/keypoint_classifier.keras'\n",
        "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5oMH7x19hEz"
      },
      "source": [
        "# Set number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "du4kodXL9hEz"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjnL0uso9hEz"
      },
      "source": [
        "# Dataset reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "QT5ZqtEz9hE0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8874, 42)"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))\n",
        "X_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "QmoKFsp49hE0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8874,)"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))\n",
        "y_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "xQU7JTZ_9hE0"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxK_lETT9hE0"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "vHBmUf1t9hE1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(42,)),  # 21 landmarks × x,y\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypqky9tc9hE1",
        "outputId": "5db082bb-30e3-4110-bf63-a1ee777ecd46"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,504</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m5,504\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m520\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,072</span> (125.28 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,072\u001b[0m (125.28 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,432</span> (122.78 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,432\u001b[0m (122.78 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "MbMjOflQ9hE1"
      },
      "outputs": [],
      "source": [
        "# Model checkpoint callback\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False)\n",
        "# Callback for early stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=40, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available gestures: ['Open', 'Close', 'One', 'OK', 'Pinch', 'Two', 'Three', 'Four']\n",
            "Gesture classifier setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Load gesture labels and create a complete hand gesture detector\n",
        "import csv\n",
        "import os\n",
        "\n",
        "def load_labels(label_path):\n",
        "    with open(label_path, encoding='utf-8-sig') as f:\n",
        "        labels = csv.reader(f)\n",
        "        labels = [row[0] for row in labels]\n",
        "    return labels\n",
        "\n",
        "# Load the gesture labels\n",
        "hand_gesture_path = \"\"\n",
        "label_path = os.path.join(hand_gesture_path, 'model/keypoint_classifier/keypoint_classifier_label.csv')\n",
        "gesture_labels = load_labels(label_path)\n",
        "\n",
        "print(\"Available gestures:\", gesture_labels)\n",
        "\n",
        "# Map the model's gestures to your game actions\n",
        "MODEL_TO_GAME_GESTURE_MAP = {\n",
        "    'Open': 'open_palm',\n",
        "    'Close': 'fist', \n",
        "    'Pointer': 'one_finger_point',\n",
        "    'OK': 'ok'\n",
        "}\n",
        "\n",
        "def classify_gesture(landmark_list):\n",
        "    \"\"\"\n",
        "    Classify hand gesture from landmark list\n",
        "    landmark_list: normalized landmark coordinates (21 points * 2 coordinates = 42 values)\n",
        "    \"\"\"\n",
        "    gesture_id = keypoint_classifier(landmark_list)\n",
        "    gesture_name = gesture_labels[gesture_id]\n",
        "    game_gesture = MODEL_TO_GAME_GESTURE_MAP.get(gesture_name, 'unknown')\n",
        "    return gesture_name, game_gesture\n",
        "\n",
        "print(\"Gesture classifier setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "c3Dac0M_9hE2"
      },
      "outputs": [],
      "source": [
        "# Model compilation\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XI0j1Iu9hE2"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WirBl-JE9hE3",
        "outputId": "71b30ca2-8294-4d9d-8aa2-800d90d399de",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m40/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2788 - loss: 2.4282\n",
            "Epoch 1: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3258 - loss: 2.2869 - val_accuracy: 0.5949 - val_loss: 1.8909\n",
            "Epoch 2/1000\n",
            "\u001b[1m40/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 1.0953\n",
            "Epoch 2: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7427 - loss: 1.0703 - val_accuracy: 0.6580 - val_loss: 1.6451\n",
            "Epoch 3/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8411 - loss: 0.7820\n",
            "Epoch 3: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.7814 - val_accuracy: 0.6507 - val_loss: 1.4628\n",
            "Epoch 4/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8778 - loss: 0.6632\n",
            "Epoch 4: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8781 - loss: 0.6615 - val_accuracy: 0.7048 - val_loss: 1.2412\n",
            "Epoch 5/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8960 - loss: 0.6227\n",
            "Epoch 5: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8991 - loss: 0.6098 - val_accuracy: 0.7404 - val_loss: 1.0576\n",
            "Epoch 6/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9158 - loss: 0.5428\n",
            "Epoch 6: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9162 - loss: 0.5419 - val_accuracy: 0.7891 - val_loss: 0.8450\n",
            "Epoch 7/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9305 - loss: 0.4829\n",
            "Epoch 7: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9304 - loss: 0.4833 - val_accuracy: 0.9031 - val_loss: 0.6196\n",
            "Epoch 8/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9427 - loss: 0.4479\n",
            "Epoch 8: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9419 - loss: 0.4483 - val_accuracy: 0.9198 - val_loss: 0.5133\n",
            "Epoch 9/1000\n",
            "\u001b[1m44/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9426 - loss: 0.4369 \n",
            "Epoch 9: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9423 - loss: 0.4375 - val_accuracy: 0.9567 - val_loss: 0.4046\n",
            "Epoch 10/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9463 - loss: 0.4148\n",
            "Epoch 10: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9460 - loss: 0.4155 - val_accuracy: 0.9689 - val_loss: 0.3501\n",
            "Epoch 11/1000\n",
            "\u001b[1m39/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.4105\n",
            "Epoch 11: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.4070 - val_accuracy: 0.9698 - val_loss: 0.3281\n",
            "Epoch 12/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.3906\n",
            "Epoch 12: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9496 - loss: 0.3899 - val_accuracy: 0.9721 - val_loss: 0.3157\n",
            "Epoch 13/1000\n",
            "\u001b[1m45/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9551 - loss: 0.3742\n",
            "Epoch 13: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9551 - loss: 0.3738 - val_accuracy: 0.9716 - val_loss: 0.3081\n",
            "Epoch 14/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9580 - loss: 0.3601\n",
            "Epoch 14: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9582 - loss: 0.3592 - val_accuracy: 0.9766 - val_loss: 0.2884\n",
            "Epoch 15/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9657 - loss: 0.3351 \n",
            "Epoch 15: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9636 - loss: 0.3356 - val_accuracy: 0.9730 - val_loss: 0.2954\n",
            "Epoch 16/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9626 - loss: 0.3290 \n",
            "Epoch 16: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.3300 - val_accuracy: 0.9748 - val_loss: 0.2747\n",
            "Epoch 17/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9604 - loss: 0.3170\n",
            "Epoch 17: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9603 - loss: 0.3173 - val_accuracy: 0.9793 - val_loss: 0.2577\n",
            "Epoch 18/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9637 - loss: 0.3081\n",
            "Epoch 18: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9638 - loss: 0.3081 - val_accuracy: 0.9815 - val_loss: 0.2524\n",
            "Epoch 19/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.3276 \n",
            "Epoch 19: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9585 - loss: 0.3186 - val_accuracy: 0.9797 - val_loss: 0.2481\n",
            "Epoch 20/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9598 - loss: 0.3133\n",
            "Epoch 20: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9613 - loss: 0.3091 - val_accuracy: 0.9815 - val_loss: 0.2394\n",
            "Epoch 21/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9700 - loss: 0.2794\n",
            "Epoch 21: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9692 - loss: 0.2809 - val_accuracy: 0.9802 - val_loss: 0.2334\n",
            "Epoch 22/1000\n",
            "\u001b[1m44/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.2809\n",
            "Epoch 22: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9685 - loss: 0.2813 - val_accuracy: 0.9820 - val_loss: 0.2338\n",
            "Epoch 23/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.2617\n",
            "Epoch 23: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9732 - loss: 0.2625 - val_accuracy: 0.9802 - val_loss: 0.2362\n",
            "Epoch 24/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9664 - loss: 0.2643\n",
            "Epoch 24: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.2643 - val_accuracy: 0.9829 - val_loss: 0.2168\n",
            "Epoch 25/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.2534\n",
            "Epoch 25: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9732 - loss: 0.2540 - val_accuracy: 0.9824 - val_loss: 0.2237\n",
            "Epoch 26/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9662 - loss: 0.2546\n",
            "Epoch 26: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9664 - loss: 0.2542 - val_accuracy: 0.9811 - val_loss: 0.2161\n",
            "Epoch 27/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9745 - loss: 0.2315\n",
            "Epoch 27: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9743 - loss: 0.2320 - val_accuracy: 0.9802 - val_loss: 0.2132\n",
            "Epoch 28/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.2364 \n",
            "Epoch 28: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9704 - loss: 0.2358 - val_accuracy: 0.9815 - val_loss: 0.2153\n",
            "Epoch 29/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9686 - loss: 0.2426 \n",
            "Epoch 29: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.2373 - val_accuracy: 0.9829 - val_loss: 0.2003\n",
            "Epoch 30/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9708 - loss: 0.2275\n",
            "Epoch 30: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9708 - loss: 0.2276 - val_accuracy: 0.9842 - val_loss: 0.1942\n",
            "Epoch 31/1000\n",
            "\u001b[1m45/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9735 - loss: 0.2198\n",
            "Epoch 31: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 0.2202 - val_accuracy: 0.9820 - val_loss: 0.2003\n",
            "Epoch 32/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.2173 \n",
            "Epoch 32: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.2176 - val_accuracy: 0.9833 - val_loss: 0.1922\n",
            "Epoch 33/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9736 - loss: 0.2087 \n",
            "Epoch 33: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9724 - loss: 0.2131 - val_accuracy: 0.9851 - val_loss: 0.1851\n",
            "Epoch 34/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.2291 \n",
            "Epoch 34: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9709 - loss: 0.2228 - val_accuracy: 0.9788 - val_loss: 0.1986\n",
            "Epoch 35/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.1953 \n",
            "Epoch 35: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.1989 - val_accuracy: 0.9829 - val_loss: 0.1794\n",
            "Epoch 36/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9743 - loss: 0.2099 \n",
            "Epoch 36: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 0.2053 - val_accuracy: 0.9820 - val_loss: 0.1843\n",
            "Epoch 37/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.2021\n",
            "Epoch 37: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9749 - loss: 0.2020 - val_accuracy: 0.9856 - val_loss: 0.1716\n",
            "Epoch 38/1000\n",
            "\u001b[1m23/52\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9714 - loss: 0.2019 \n",
            "Epoch 38: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.1905 - val_accuracy: 0.9869 - val_loss: 0.1627\n",
            "Epoch 39/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.1730 \n",
            "Epoch 39: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.1777 - val_accuracy: 0.9874 - val_loss: 0.1664\n",
            "Epoch 40/1000\n",
            "\u001b[1m40/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 0.1976\n",
            "Epoch 40: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9745 - loss: 0.1964 - val_accuracy: 0.9802 - val_loss: 0.1837\n",
            "Epoch 41/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9756 - loss: 0.1887\n",
            "Epoch 41: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9756 - loss: 0.1886 - val_accuracy: 0.9829 - val_loss: 0.1667\n",
            "Epoch 42/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.1975 \n",
            "Epoch 42: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9726 - loss: 0.1929 - val_accuracy: 0.9847 - val_loss: 0.1698\n",
            "Epoch 43/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9745 - loss: 0.1807 \n",
            "Epoch 43: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9755 - loss: 0.1827 - val_accuracy: 0.9824 - val_loss: 0.1651\n",
            "Epoch 44/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.1591\n",
            "Epoch 44: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9832 - loss: 0.1592 - val_accuracy: 0.9865 - val_loss: 0.1540\n",
            "Epoch 45/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9757 - loss: 0.1727\n",
            "Epoch 45: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9757 - loss: 0.1728 - val_accuracy: 0.9842 - val_loss: 0.1626\n",
            "Epoch 46/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.1738 \n",
            "Epoch 46: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9736 - loss: 0.1719 - val_accuracy: 0.9811 - val_loss: 0.1652\n",
            "Epoch 47/1000\n",
            "\u001b[1m45/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.1495\n",
            "Epoch 47: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.1505 - val_accuracy: 0.9856 - val_loss: 0.1551\n",
            "Epoch 48/1000\n",
            "\u001b[1m34/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9814 - loss: 0.1573\n",
            "Epoch 48: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.1567 - val_accuracy: 0.9874 - val_loss: 0.1520\n",
            "Epoch 49/1000\n",
            "\u001b[1m43/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.1663\n",
            "Epoch 49: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9763 - loss: 0.1665 - val_accuracy: 0.9842 - val_loss: 0.1500\n",
            "Epoch 50/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9752 - loss: 0.1715 \n",
            "Epoch 50: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.1737 - val_accuracy: 0.9802 - val_loss: 0.1676\n",
            "Epoch 51/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.2096 \n",
            "Epoch 51: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9647 - loss: 0.1982 - val_accuracy: 0.9820 - val_loss: 0.1522\n",
            "Epoch 52/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.1599\n",
            "Epoch 52: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.1602 - val_accuracy: 0.9829 - val_loss: 0.1539\n",
            "Epoch 53/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.1592\n",
            "Epoch 53: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.1592 - val_accuracy: 0.9797 - val_loss: 0.1631\n",
            "Epoch 54/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.1408 \n",
            "Epoch 54: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9824 - loss: 0.1487 - val_accuracy: 0.9856 - val_loss: 0.1449\n",
            "Epoch 55/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9738 - loss: 0.1607\n",
            "Epoch 55: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9749 - loss: 0.1591 - val_accuracy: 0.9833 - val_loss: 0.1459\n",
            "Epoch 56/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.1467\n",
            "Epoch 56: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.1471 - val_accuracy: 0.9820 - val_loss: 0.1483\n",
            "Epoch 57/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.1515 \n",
            "Epoch 57: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.1547 - val_accuracy: 0.9847 - val_loss: 0.1467\n",
            "Epoch 58/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.1436\n",
            "Epoch 58: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9801 - loss: 0.1442 - val_accuracy: 0.9806 - val_loss: 0.1527\n",
            "Epoch 59/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9782 - loss: 0.1550\n",
            "Epoch 59: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9782 - loss: 0.1553 - val_accuracy: 0.9865 - val_loss: 0.1440\n",
            "Epoch 60/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.1559\n",
            "Epoch 60: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9777 - loss: 0.1561 - val_accuracy: 0.9820 - val_loss: 0.1503\n",
            "Epoch 61/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.1468\n",
            "Epoch 61: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.1465 - val_accuracy: 0.9856 - val_loss: 0.1383\n",
            "Epoch 62/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.1437\n",
            "Epoch 62: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.1437 - val_accuracy: 0.9860 - val_loss: 0.1347\n",
            "Epoch 63/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9794 - loss: 0.1414\n",
            "Epoch 63: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9794 - loss: 0.1417 - val_accuracy: 0.9824 - val_loss: 0.1519\n",
            "Epoch 64/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.1464\n",
            "Epoch 64: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9780 - loss: 0.1465 - val_accuracy: 0.9851 - val_loss: 0.1405\n",
            "Epoch 65/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.1436 \n",
            "Epoch 65: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.1433 - val_accuracy: 0.9860 - val_loss: 0.1302\n",
            "Epoch 66/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.1432\n",
            "Epoch 66: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.1433 - val_accuracy: 0.9838 - val_loss: 0.1375\n",
            "Epoch 67/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.1428\n",
            "Epoch 67: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.1428 - val_accuracy: 0.9869 - val_loss: 0.1317\n",
            "Epoch 68/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9791 - loss: 0.1452\n",
            "Epoch 68: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.1460 - val_accuracy: 0.9860 - val_loss: 0.1329\n",
            "Epoch 69/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.1453 \n",
            "Epoch 69: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.1442 - val_accuracy: 0.9838 - val_loss: 0.1359\n",
            "Epoch 70/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.1431\n",
            "Epoch 70: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9806 - loss: 0.1435 - val_accuracy: 0.9851 - val_loss: 0.1383\n",
            "Epoch 71/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.1497\n",
            "Epoch 71: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9797 - loss: 0.1493 - val_accuracy: 0.9820 - val_loss: 0.1412\n",
            "Epoch 72/1000\n",
            "\u001b[1m39/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.1332\n",
            "Epoch 72: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9824 - loss: 0.1350 - val_accuracy: 0.9838 - val_loss: 0.1439\n",
            "Epoch 73/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.1429\n",
            "Epoch 73: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.1428 - val_accuracy: 0.9833 - val_loss: 0.1323\n",
            "Epoch 74/1000\n",
            "\u001b[1m39/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.1368\n",
            "Epoch 74: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.1382 - val_accuracy: 0.9833 - val_loss: 0.1371\n",
            "Epoch 75/1000\n",
            "\u001b[1m32/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.1324 \n",
            "Epoch 75: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.1366 - val_accuracy: 0.9838 - val_loss: 0.1347\n",
            "Epoch 76/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9757 - loss: 0.1534\n",
            "Epoch 76: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9757 - loss: 0.1533 - val_accuracy: 0.9869 - val_loss: 0.1340\n",
            "Epoch 77/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.1493\n",
            "Epoch 77: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9780 - loss: 0.1492 - val_accuracy: 0.9860 - val_loss: 0.1351\n",
            "Epoch 78/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.1333\n",
            "Epoch 78: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9812 - loss: 0.1340 - val_accuracy: 0.9869 - val_loss: 0.1257\n",
            "Epoch 79/1000\n",
            "\u001b[1m41/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.1478\n",
            "Epoch 79: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9796 - loss: 0.1455 - val_accuracy: 0.9851 - val_loss: 0.1254\n",
            "Epoch 80/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.1357\n",
            "Epoch 80: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.1358 - val_accuracy: 0.9851 - val_loss: 0.1329\n",
            "Epoch 81/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.1264\n",
            "Epoch 81: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.1279 - val_accuracy: 0.9824 - val_loss: 0.1427\n",
            "Epoch 82/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.1479 \n",
            "Epoch 82: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9773 - loss: 0.1484 - val_accuracy: 0.9860 - val_loss: 0.1338\n",
            "Epoch 83/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.1341\n",
            "Epoch 83: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.1341 - val_accuracy: 0.9824 - val_loss: 0.1328\n",
            "Epoch 84/1000\n",
            "\u001b[1m26/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9793 - loss: 0.1468 \n",
            "Epoch 84: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.1453 - val_accuracy: 0.9860 - val_loss: 0.1341\n",
            "Epoch 85/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.1350 \n",
            "Epoch 85: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.1345 - val_accuracy: 0.9847 - val_loss: 0.1370\n",
            "Epoch 86/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9860 - loss: 0.1209\n",
            "Epoch 86: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.1215 - val_accuracy: 0.9860 - val_loss: 0.1270\n",
            "Epoch 87/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.1374\n",
            "Epoch 87: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.1369 - val_accuracy: 0.9838 - val_loss: 0.1363\n",
            "Epoch 88/1000\n",
            "\u001b[1m40/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.1245\n",
            "Epoch 88: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9831 - loss: 0.1253 - val_accuracy: 0.9869 - val_loss: 0.1277\n",
            "Epoch 89/1000\n",
            "\u001b[1m44/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.1342\n",
            "Epoch 89: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9814 - loss: 0.1330 - val_accuracy: 0.9842 - val_loss: 0.1312\n",
            "Epoch 90/1000\n",
            "\u001b[1m36/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9795 - loss: 0.1379\n",
            "Epoch 90: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9799 - loss: 0.1367 - val_accuracy: 0.9856 - val_loss: 0.1249\n",
            "Epoch 91/1000\n",
            "\u001b[1m43/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9815 - loss: 0.1296\n",
            "Epoch 91: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.1299 - val_accuracy: 0.9883 - val_loss: 0.1261\n",
            "Epoch 92/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.1203 \n",
            "Epoch 92: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.1222 - val_accuracy: 0.9856 - val_loss: 0.1253\n",
            "Epoch 93/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.1280\n",
            "Epoch 93: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.1281 - val_accuracy: 0.9887 - val_loss: 0.1144\n",
            "Epoch 94/1000\n",
            "\u001b[1m37/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9799 - loss: 0.1278\n",
            "Epoch 94: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9801 - loss: 0.1292 - val_accuracy: 0.9874 - val_loss: 0.1186\n",
            "Epoch 95/1000\n",
            "\u001b[1m38/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.1239\n",
            "Epoch 95: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9835 - loss: 0.1248 - val_accuracy: 0.9851 - val_loss: 0.1254\n",
            "Epoch 96/1000\n",
            "\u001b[1m43/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.1185\n",
            "Epoch 96: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9836 - loss: 0.1189 - val_accuracy: 0.9851 - val_loss: 0.1281\n",
            "Epoch 97/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.1214\n",
            "Epoch 97: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9822 - loss: 0.1217 - val_accuracy: 0.9896 - val_loss: 0.1207\n",
            "Epoch 98/1000\n",
            "\u001b[1m36/52\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.1138\n",
            "Epoch 98: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.1182 - val_accuracy: 0.9865 - val_loss: 0.1254\n",
            "Epoch 99/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9781 - loss: 0.1408\n",
            "Epoch 99: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9782 - loss: 0.1403 - val_accuracy: 0.9856 - val_loss: 0.1341\n",
            "Epoch 100/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9865 - loss: 0.1183\n",
            "Epoch 100: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.1185 - val_accuracy: 0.9860 - val_loss: 0.1248\n",
            "Epoch 101/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.1231\n",
            "Epoch 101: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.1245 - val_accuracy: 0.9869 - val_loss: 0.1247\n",
            "Epoch 102/1000\n",
            "\u001b[1m39/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9844 - loss: 0.1215\n",
            "Epoch 102: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9839 - loss: 0.1225 - val_accuracy: 0.9883 - val_loss: 0.1156\n",
            "Epoch 103/1000\n",
            "\u001b[1m44/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.1234\n",
            "Epoch 103: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.1232 - val_accuracy: 0.9842 - val_loss: 0.1320\n",
            "Epoch 104/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.1200\n",
            "Epoch 104: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.1202 - val_accuracy: 0.9860 - val_loss: 0.1218\n",
            "Epoch 105/1000\n",
            "\u001b[1m39/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.1197\n",
            "Epoch 105: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.1203 - val_accuracy: 0.9856 - val_loss: 0.1326\n",
            "Epoch 106/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.1237\n",
            "Epoch 106: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9844 - loss: 0.1241 - val_accuracy: 0.9865 - val_loss: 0.1253\n",
            "Epoch 107/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.1284\n",
            "Epoch 107: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.1284 - val_accuracy: 0.9878 - val_loss: 0.1240\n",
            "Epoch 108/1000\n",
            "\u001b[1m41/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9883 - loss: 0.1146\n",
            "Epoch 108: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9881 - loss: 0.1144 - val_accuracy: 0.9851 - val_loss: 0.1286\n",
            "Epoch 109/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.1211\n",
            "Epoch 109: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9824 - loss: 0.1211 - val_accuracy: 0.9860 - val_loss: 0.1188\n",
            "Epoch 110/1000\n",
            "\u001b[1m29/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.1152 \n",
            "Epoch 110: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.1175 - val_accuracy: 0.9856 - val_loss: 0.1344\n",
            "Epoch 111/1000\n",
            "\u001b[1m41/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.1248\n",
            "Epoch 111: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.1254 - val_accuracy: 0.9865 - val_loss: 0.1211\n",
            "Epoch 112/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.1262\n",
            "Epoch 112: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9824 - loss: 0.1264 - val_accuracy: 0.9838 - val_loss: 0.1298\n",
            "Epoch 113/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.1155\n",
            "Epoch 113: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9834 - loss: 0.1158 - val_accuracy: 0.9883 - val_loss: 0.1179\n",
            "Epoch 114/1000\n",
            "\u001b[1m25/52\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.1257 \n",
            "Epoch 114: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.1263 - val_accuracy: 0.9851 - val_loss: 0.1215\n",
            "Epoch 115/1000\n",
            "\u001b[1m37/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9800 - loss: 0.1343 \n",
            "Epoch 115: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.1360 - val_accuracy: 0.9856 - val_loss: 0.1222\n",
            "Epoch 116/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9811 - loss: 0.1298 \n",
            "Epoch 116: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.1273 - val_accuracy: 0.9860 - val_loss: 0.1250\n",
            "Epoch 117/1000\n",
            "\u001b[1m38/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9873 - loss: 0.1167\n",
            "Epoch 117: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9866 - loss: 0.1173 - val_accuracy: 0.9869 - val_loss: 0.1256\n",
            "Epoch 118/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9805 - loss: 0.1331 \n",
            "Epoch 118: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9805 - loss: 0.1329 - val_accuracy: 0.9865 - val_loss: 0.1110\n",
            "Epoch 119/1000\n",
            "\u001b[1m39/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.1218\n",
            "Epoch 119: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9820 - loss: 0.1231 - val_accuracy: 0.9842 - val_loss: 0.1430\n",
            "Epoch 120/1000\n",
            "\u001b[1m45/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.1293\n",
            "Epoch 120: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9808 - loss: 0.1296 - val_accuracy: 0.9865 - val_loss: 0.1243\n",
            "Epoch 121/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.1259\n",
            "Epoch 121: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.1256 - val_accuracy: 0.9838 - val_loss: 0.1304\n",
            "Epoch 122/1000\n",
            "\u001b[1m27/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.1296 \n",
            "Epoch 122: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9829 - loss: 0.1253 - val_accuracy: 0.9869 - val_loss: 0.1179\n",
            "Epoch 123/1000\n",
            "\u001b[1m43/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.1283\n",
            "Epoch 123: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9808 - loss: 0.1294 - val_accuracy: 0.9865 - val_loss: 0.1242\n",
            "Epoch 124/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.1169\n",
            "Epoch 124: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9831 - loss: 0.1193 - val_accuracy: 0.9847 - val_loss: 0.1311\n",
            "Epoch 125/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.1363\n",
            "Epoch 125: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9790 - loss: 0.1339 - val_accuracy: 0.9874 - val_loss: 0.1168\n",
            "Epoch 126/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.1235\n",
            "Epoch 126: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.1230 - val_accuracy: 0.9869 - val_loss: 0.1234\n",
            "Epoch 127/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.1197 \n",
            "Epoch 127: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.1217 - val_accuracy: 0.9869 - val_loss: 0.1226\n",
            "Epoch 128/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.1321\n",
            "Epoch 128: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.1320 - val_accuracy: 0.9860 - val_loss: 0.1224\n",
            "Epoch 129/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.1122\n",
            "Epoch 129: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9877 - loss: 0.1133 - val_accuracy: 0.9829 - val_loss: 0.1401\n",
            "Epoch 130/1000\n",
            "\u001b[1m43/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.1074\n",
            "Epoch 130: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.1091 - val_accuracy: 0.9865 - val_loss: 0.1127\n",
            "Epoch 131/1000\n",
            "\u001b[1m45/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.1061\n",
            "Epoch 131: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.1070 - val_accuracy: 0.9874 - val_loss: 0.1182\n",
            "Epoch 132/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.1152 \n",
            "Epoch 132: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.1169 - val_accuracy: 0.9856 - val_loss: 0.1249\n",
            "Epoch 133/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9856 - loss: 0.1119\n",
            "Epoch 133: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.1118 - val_accuracy: 0.9865 - val_loss: 0.1134\n",
            "Epoch 134/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.1105\n",
            "Epoch 134: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9832 - loss: 0.1107 - val_accuracy: 0.9847 - val_loss: 0.1302\n",
            "Epoch 135/1000\n",
            "\u001b[1m48/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9805 - loss: 0.1248\n",
            "Epoch 135: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.1249 - val_accuracy: 0.9851 - val_loss: 0.1303\n",
            "Epoch 136/1000\n",
            "\u001b[1m41/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.1129\n",
            "Epoch 136: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9845 - loss: 0.1147 - val_accuracy: 0.9842 - val_loss: 0.1329\n",
            "Epoch 137/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.1239\n",
            "Epoch 137: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.1239 - val_accuracy: 0.9865 - val_loss: 0.1212\n",
            "Epoch 138/1000\n",
            "\u001b[1m33/52\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.1216 \n",
            "Epoch 138: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.1229 - val_accuracy: 0.9833 - val_loss: 0.1318\n",
            "Epoch 139/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9816 - loss: 0.1195\n",
            "Epoch 139: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.1198 - val_accuracy: 0.9851 - val_loss: 0.1229\n",
            "Epoch 140/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.1225\n",
            "Epoch 140: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.1235 - val_accuracy: 0.9811 - val_loss: 0.1296\n",
            "Epoch 141/1000\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9788 - loss: 0.1317\n",
            "Epoch 141: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.1316 - val_accuracy: 0.9856 - val_loss: 0.1216\n",
            "Epoch 142/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.1239\n",
            "Epoch 142: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9814 - loss: 0.1237 - val_accuracy: 0.9865 - val_loss: 0.1191\n",
            "Epoch 143/1000\n",
            "\u001b[1m45/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.1186\n",
            "Epoch 143: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9843 - loss: 0.1182 - val_accuracy: 0.9874 - val_loss: 0.1186\n",
            "Epoch 144/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.1079\n",
            "Epoch 144: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.1081 - val_accuracy: 0.9865 - val_loss: 0.1232\n",
            "Epoch 145/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.1111\n",
            "Epoch 145: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.1116 - val_accuracy: 0.9878 - val_loss: 0.1142\n",
            "Epoch 146/1000\n",
            "\u001b[1m51/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9800 - loss: 0.1278\n",
            "Epoch 146: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9801 - loss: 0.1277 - val_accuracy: 0.9892 - val_loss: 0.1207\n",
            "Epoch 147/1000\n",
            "\u001b[1m30/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.1247 \n",
            "Epoch 147: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.1245 - val_accuracy: 0.9860 - val_loss: 0.1259\n",
            "Epoch 148/1000\n",
            "\u001b[1m42/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9853 - loss: 0.1170\n",
            "Epoch 148: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.1170 - val_accuracy: 0.9856 - val_loss: 0.1263\n",
            "Epoch 149/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9854 - loss: 0.1100\n",
            "Epoch 149: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.1102 - val_accuracy: 0.9833 - val_loss: 0.1277\n",
            "Epoch 150/1000\n",
            "\u001b[1m47/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9789 - loss: 0.1340\n",
            "Epoch 150: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9793 - loss: 0.1326 - val_accuracy: 0.9824 - val_loss: 0.1328\n",
            "Epoch 151/1000\n",
            "\u001b[1m49/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.1058\n",
            "Epoch 151: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.1064 - val_accuracy: 0.9856 - val_loss: 0.1204\n",
            "Epoch 152/1000\n",
            "\u001b[1m41/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.1169\n",
            "Epoch 152: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.1179 - val_accuracy: 0.9860 - val_loss: 0.1191\n",
            "Epoch 153/1000\n",
            "\u001b[1m46/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.1270\n",
            "Epoch 153: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9827 - loss: 0.1268 - val_accuracy: 0.9892 - val_loss: 0.1147\n",
            "Epoch 154/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9863 - loss: 0.1092 \n",
            "Epoch 154: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.1098 - val_accuracy: 0.9847 - val_loss: 0.1347\n",
            "Epoch 155/1000\n",
            "\u001b[1m31/52\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9856 - loss: 0.1208 \n",
            "Epoch 155: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.1176 - val_accuracy: 0.9860 - val_loss: 0.1178\n",
            "Epoch 156/1000\n",
            "\u001b[1m28/52\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.1184 \n",
            "Epoch 156: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9836 - loss: 0.1205 - val_accuracy: 0.9856 - val_loss: 0.1330\n",
            "Epoch 157/1000\n",
            "\u001b[1m50/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9789 - loss: 0.1294\n",
            "Epoch 157: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9790 - loss: 0.1296 - val_accuracy: 0.9847 - val_loss: 0.1200\n",
            "Epoch 158/1000\n",
            "\u001b[1m39/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9803 - loss: 0.1260\n",
            "Epoch 158: saving model to model/keypoint_classifier/keypoint_classifier.keras\n",
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9804 - loss: 0.1271 - val_accuracy: 0.9878 - val_loss: 0.1181\n",
            "Epoch 158: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x31dbff110>"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[cp_callback, es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxvb2Y299hE3",
        "outputId": "59eb3185-2e37-4b9e-bc9d-ab1b8ac29b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9861 - loss: 0.1307 \n"
          ]
        }
      ],
      "source": [
        "# Model evaluation\n",
        "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "RBkmDeUW9hE4"
      },
      "outputs": [],
      "source": [
        "# Loading the saved model\n",
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFz9Tb0I9hE4",
        "outputId": "1c3b3528-54ae-4ee2-ab04-77429211cbef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677ms/step\n",
            "[1.5660289e-07 3.2982084e-06 4.6129417e-06 1.2158740e-06 1.2317237e-05\n",
            " 9.9826694e-01 1.7079986e-03 3.3834465e-06]\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "# Inference test\n",
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3U4yNWx9hE4"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (2.3.1)\n",
            "Requirement already satisfied: seaborn in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (3.10.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas seaborn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "AP1V6SCk9hE5",
        "outputId": "08e41a80-7a4a-4619-8125-ecc371368d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAH7CAYAAADb3QX/AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVetJREFUeJzt3Qd4FNXaB/D/pjcSSA9gkCK9B4RIkyKhd7wqTUEUBAQixQjS5BKko9JUpCiIwBWlt1CkRUIogQBBmqGlEUhIIHX3e+b4ZWXdIATYZM/s/3efczc7M5mdw67Jm/e854xGp9PpQERERCQxq6K+ACIiIqJnxYCGiIiIpMeAhoiIiKTHgIaIiIikx4CGiIiIpMeAhoiIiKTHgIaIiIikx4CGiIiIpMeAhoiIiKTHgIaIiIikZwMzkZ10GWrkWLJJUV8CEREVgpysG6r4nWnrWe6pvm/69OkICQnB8OHDMW/ePLEtIyMDH330EdasWYPMzEwEBQVh4cKF8PHx0X9fbGwsBg8ejL1798LFxQX9+vVDaGgobGwKFqIwQ0NERETPJCIiAkuWLEHNmjUNto8cORKbNm3CunXrsH//fty8eRPdunXT78/NzUX79u2RlZWFw4cPY8WKFVi+fDkmTJhQ4GtgQENERCQbba7pWgGlpaWhV69e+Oabb1CiRAn99pSUFCxduhRz5sxBixYtEBAQgGXLlonAJTw8XByzc+dOnD17Fj/88ANq166Ntm3b4rPPPsOCBQtEkFMQDGiIiIhITxkaSk1NNWjKtkcZMmSIyLK0atXKYHtkZCSys7MNtleuXBn+/v44cuSIeK481qhRw2AIShmWUl4zOjoaBcGAhoiISDY6rclaaGgo3NzcDJqyLT9Kbczx48fz3R8XFwc7OzsUL17cYLsSvCj78o55OJjJ25+3T8qiYCIiIip6ISEhCA4ONthmb29vdNy1a9dEAfCuXbvg4OCAosaAhoiISDZarclObW9vn28A80/KkFJCQgLq1q1rUOT722+/4auvvsKOHTtEHczdu3cNsjTx8fHw9fUVXyuPR48eNTivsj9vX0FwyImIiEgyOp3WZO1JtWzZEqdPn8bJkyf1rV69eqJAOO9rW1tbhIWF6b8nJiZGTNMODAwUz5VH5RxKYJRHyfi4urqiatWqKAhmaIiIiKjAihUrhurVqxtsc3Z2hoeHh377gAEDxPCVu7u7CFKGDRsmgpiGDRuK/a1btxaBS58+fTBjxgxRNzN+/HhRaPwkWaKHMaAhIiKSjQmHnJ6nuXPnwsrKCt27dzdYWC+PtbU1Nm/eLBbWUwIdJSBSFtabMmVKgV9Lo9PpdDADXCmYiIhkVpgrBWddP22yc9uVrgEZMUNDREQkmwLUulgKFgUTERGR9JihISIiks1T3KJA7ZihISIiIukxQ0NERCQb1tAYYYaGiIiIpMcMDRERkWwkWYemMDGgISIikkxBblFgKTjkRERERNJjhoaIiEg2HHIywgwNERERSY8ZGiIiItmwhsYIMzREREQkPdUFNN9+vxbVG7XF9HmL9dsyM7MwdfYCNGr7Ouq36ooRn0xFUvId/f67Kal4P3g8mnfqhTqvdkTLrn3w39kLkZaeDlkMHtQPFy+EIy31Eg4f3IT69WpDZk0aN8AvG5Yj9mqkuINtp05BUBO1vV9q75ea+8Z+SXzrA1M1SakqoDl9Lgbrft2KihXKGmz//Isl2Hfod8yZ+gmWfzUDiUm3RVCTR6PRoHmThvjy84nYsuZb/HdcMMKPncCUmV9BBj17dsKsmRPx2dQ5qN+gDU5FncXWLavg5eUBWTk7OyEq6iyGDR8HtVHj+6Xmfqm5b+wXqYlGp9PpYAayky4/0/ffv/8APfsPw/iPhmDJih9RuUI5fDxiEO6lpaNJ+zcwY9IYtG7eRBx7+c9r6PTWe1i1ZA5qVa+S7/l+WPcrlq1ej7AN3z/TdTmW/Os1TUn56yPi2CkMHzFeH6BdvRyBBQuXYcbMBZCdkqHp1qM/Nm7cATVQ6/ul1n6puW/s1/P/WVVYMs/tNdm57as0h0VkaJKSkjBjxgx07doVgYGBoilfz5w5E4mJiSgqypBS08D6CKxfx2D72Zg/kJOTg4b1/t5erswL8PPxxqkz5/M9V0Libezefwj1ateAubO1tUXdujURtueAfpsSo4btOYiGDQOK9NrIct4vtfZLzX1jv1QwbdtUTVIFCmgiIiJQsWJFfPHFF3Bzc0PTpk1FU75WtlWuXBnHjh177HkyMzORmppq0JRtT2vr7n04d+ESRgx6x2hf0u07sLW1gWsxF4PtHu7FkZScbLBt9MTpqNeiC1p06Q0XJydM+XgEzJ2npztsbGyQEJ9ksD0hIRG+Pl5Fdl1kWe+XWvul5r6xX2TR07aHDRuGnj17YvHixSKF9zAlAh40aJA45siRI/96ntDQUEyePNlg2/jRH2LCmOEoqFvxiZg+bwm+mTcN9vZ2eBZjP3wPg/v3wp+xNzBv8TLM+PJrfDpq6DOdk4iI6LnjtO1nC2hOnTqF5cuXGwUzCmXbyJEjUaeO4ZBPfkJCQhAcHGywzere0409KkNKyXfu4vX+fwceublaRJ48gx9/3oQlc6YiOzsHqffSDLI0t5PvwtPd3eBcnh7uoilDUm6uLuj7wWgMevsteHkaHmdOkpKSxZCat4+nwXZvby/ExRfdECBZ1vul1n6puW/sF6lNgYacfH19cfTo0UfuV/b5+Pg89jz29vZwdXU1aMq2p9EwoDY2fL8I65cv0LdqlV9C+9bN///riiL9+Puxk/rvufLnddyKT0Ct6pUfeV7t/9dKZ2Vnw5xlZ2fj+PEotGje2CC4VJ6Hh0cW6bWR5bxfau2XmvvGfkmONTTPlqEZNWoU3nvvPURGRqJly5b64CU+Ph5hYWH45ptvMGvWLBT29N6Xyr1osM3R0QHFXYvpt3fr0BozvvwGbq7FxPHT5i4Ss5vyZjj9dvgobt+5i+pVKsLJ0REXr/yJ2Qu+RZ2aVVHK7/EBWlGbO/8bLFs6F5HHoxARcQIfDhsIZ2dHLF/xE2SlvE8VHpp+X/ZFf9SqVQ3JyXdw7dpNyEyN75ea+6XmvrFfpCYFCmiGDBkCT09PzJ07FwsXLkRu7l8L8FhbWyMgIEAMR73++uswN2M/fB9WVlYYMU4ZfsrGKy8H4NNRQ/T7HeztsX7jdsz44mtkZWWLwrFWzV7BgN7m15f8rFu3UQyLTZowCr6+Xjh1KhrtO/RGQoJhUZxM6gXUQtju9frns2dNEo8rVq7FgHdHQmZqfL/U3C819439kpdOJ+8CeGa3Do0SGChTuBVKkKNMlSvKdWjMVWGsQ0NEREWvMNehyTi11WTndqjVDhZ1c0olgPHz83u+V0NERESPx1lORni3bSIiItlIXLxrKqq6lxMRERFZJmZoiIiIZMMhJyPM0BAREZH0mKEhIiKSjZbTtv+JGRoiIiKSHjM0REREsmENjRFmaIiIiEh6zNAQERHJhuvQGGFAQ0REJBsOORnhkBMRERFJjxkaIiIi2XDIyQgzNERERCQ9ZmiIiIhkwwyNEWZoiIiISHrM0BAREUlGp+OtD/6JGRoiIiKSHjM0REREsmENjREGNERERLLhwnpGOORERERE0mOGhoiISDYccjLCDA0RERE9lUWLFqFmzZpwdXUVLTAwENu2bdPvf/XVV6HRaAzaoEGDDM4RGxuL9u3bw8nJCd7e3hg9ejRycnLkzdA4lmwCNUo/sRJq5Fynb1FfAhGR5TKTGprSpUtj+vTpeOmll6DT6bBixQp07twZJ06cQLVq1cQxAwcOxJQpU/TfowQueXJzc0Uw4+vri8OHD+PWrVvo27cvbG1tMW3aNDkDGiIiIpJLx44dDZ7/97//FVmb8PBwfUCjBDBKwJKfnTt34uzZs9i9ezd8fHxQu3ZtfPbZZxg7diwmTZoEOzu7J74WDjkRERHJWENjopaZmYnU1FSDpmx7HCXbsmbNGqSnp4uhpzyrVq2Cp6cnqlevjpCQENy/f1+/78iRI6hRo4YIZvIEBQWJ14yOji7QPwkDGiIiItILDQ2Fm5ubQVO2Pcrp06fh4uICe3t7UR+zYcMGVK1aVex766238MMPP2Dv3r0imPn+++/Ru3dv/ffGxcUZBDOKvOfKvoLgkBMREZFsTFhDExISguDgYINtSrDyKJUqVcLJkyeRkpKC9evXo1+/fti/f78Iat577z39cUomxs/PDy1btsSlS5dQvnz553rdDGiIiIhkY8Jp2/b29v8awPyTUudSoUIF8XVAQAAiIiIwf/58LFmyxOjYBg0aiMeLFy+KgEaprTl69KjBMfHx8eLxUXU3j8IhJyIiInputP9fh5MfJZOjUDI1CqXWRhmySkhI0B+za9cuMQU8b9jqSTFDQ0REJBszWVgvJCQEbdu2hb+/P+7du4fVq1dj37592LFjhxhWUp63a9cOHh4eiIqKwsiRI9G0aVOxdo2idevWInDp06cPZsyYIepmxo8fjyFDhhQoS6RgQENERERPRcmsKOvGKOvHKMXDSqCiBDOvvfYarl27JqZjz5s3T8x8euGFF9C9e3cRsOSxtrbG5s2bMXjwYJGtcXZ2FjU4D69b86Q0OmUlHDNgY1cKasSF9YiILENO1o1Ce60Hm+eY7NyOHQwLgmXBGhoiIiKSHoeciIiIZGMmNTTmhBkaIiIikh4zNERERLIxk5tTmhMGNERERLLhkJMRDjkRERGR9JihISIikg2HnIwwQ0NERETSY4aGiIhINqyhMcIMDREREUmPGRoiIiLZMENjhBkaIiIikh4zNERERLIxj/tKmxUGNERERLLhkJNlDzkNHtQPFy+EIy31Eg4f3IT69WrDnP20/Td0HzkVgb2CRev98UwcOB4t9t1IuI2a3T7It+08fFx/jvCo8+gTMhMN3xqJ5v0/xtyVG5CTmwtZyPaeWXK/mjRugF82LEfs1UjkZN1Ap05BUBM1vmcK9ovUwmICmp49O2HWzIn4bOoc1G/QBqeizmLrllXw8vKAufLxKI4RvbtgzcyP8ePMsXi5RkUMn74YF2NvwtejBPYsDTVoH7zRAU4O9mhcp6r4/pgr1zFk6kI0qlMNa2eHYOZH/bEvIgrzvv8FMpDxPbPkfjk7OyEq6iyGDR8HtVHre8Z+SZ6hMVWTlEanM4+BOBu7UiY9vxKhRxw7heEjxovnGo0GVy9HYMHCZZgxc4HJXjf9xMrner7GfUchuG9XdGvVyGjf6x9NQ5VyL2DykD7i+fwffkX4qXP4cebH+mOUgGb07KXYt+xzODs6PPV1ONfpC1MrqvfM1NTar4cpGZpuPfpj48YdUAO1vmfs1/P/3BeWB6s+Ndm5HXt9BhlZRIbG1tYWdevWRNieA/ptShwXtucgGjYMgAxyc7XYdvAYHmRkoValckb7z16Kxfkr19G15Sv6bdnZObCzszU4zsHODplZ2eJ4c6aG98yS+qVman3P2C8V3PrAVE1Szz2guXbtGvr37/+vx2RmZiI1NdWgmTJR5OnpDhsbGyTEJxlsT0hIhK+PF8zZhT9voMFbI1HvPx9i6uIfMW/seyj/gp/RcT/vPoRypX1Ru3J5/bZX6lTBqZjL2HogQgRE8bfvYvG6rWJf4p0UmDOZ3zNL7JeaqfU9Y79IbZ57QJOcnIwVK1b86zGhoaFwc3MzaDrtved9KapQtqQP1s0OwarPx+D1Nk0w/suVuHTtlsExGZlZ2HbgmEF2RvFK7aoI7tsNU5f8KAKijkMnoUndamKflUZTqP0gIqLniDU0zz5te+PGjf+6//Lly489R0hICIKDgw22lfCoDFNJSkpGTk4OvH08DbZ7e3shLj4R5szW1gb+ft7i66rl/XHm4p9YtXkvJgx+S3/MriMn8CArCx1fbWD0/X07tUSfji1ERsbV2Qk3E2+L2prS//i3MDcyv2eW2C81U+t7xn4RLD1D06VLF3Tt2lU85tf+Gajkx97eHq6urgZNKdoylezsbBw/HoUWzRvrtymvpzwPD4+ETLRaHbJycgy2bQg7jFfr1YS7W7F8v0fpq7d7cTjY24lMjq9nCVQp5w9zpqb3zBL6pWZqfc/YL8kpZRqmapaSofHz88PChQvRuXPnfPefPHkSAQHmV3g1d/43WLZ0LiKPRyEi4gQ+HDYQzs6OWL7iJ5ir+T/8IqZc+3m5I/1BBrYdiMCx6D+w+NOh+mNibyUg8uxFLBj3Qb7nWPbLLjSqU1UMMYWFn8TSDTsx66MBsLY2/3pwGd8zS+6XMm27QoWy+udlX/RHrVrVkJx8B9eu3SzSa3tWan3P2C9SkwIHNEqwEhkZ+ciARomEzWQmuIF16zbCy9MdkyaMgq+vF06dikb7Dr2RkGBYOGZOklPuYfwXK5B4JxUuTg6o+GIpEcwE1q6iP2ZD2BGxXs0rD2172MHj0fh2/XaR1alYphTmfzxIX0dj7mR8zyy5X/UCaiFs93r989mzJonHFSvXYsC7IyEztb5n7JfEJK51MZt1aA4cOID09HS0adMm3/3KvmPHjqFZs2ZmtQ5NUXne69CYi8JYh4aISCaFug7N0lEmO7fjgFmwiAxNkyZN/nW/s7NzgYMZIiIiomfBm1MSERHJRuIF8EzF/CtDiYiIiB6DGRoiIiLJ6LTmN/mmqDFDQ0RERNJjhoaIiEg2nLZthBkaIiIikh4zNERERLLhLCcjDGiIiIhkw6JgIxxyIiIiIukxQ0NERCQbFgUbYYaGiIiIpMcMDRERkWyYoTHCDA0RERFJjxkaIiIi2eg4y+mfmKEhIiIi6TFDQ0REJBvW0BhhQENERCQbLqxnhENOREREJD1maIiIiGTDezkZYYaGiIiIpMcMDRERkWxYQ2OEGRoiIiJ6KosWLULNmjXh6uoqWmBgILZt26bfn5GRgSFDhsDDwwMuLi7o3r074uPjDc4RGxuL9u3bw8nJCd7e3hg9ejRycnIKfC3M0JiYc52+UKN7S3pBjYq9v6qoL4GI6LF0ZjJtu3Tp0pg+fTpeeukl6HQ6rFixAp07d8aJEydQrVo1jBw5Elu2bMG6devg5uaGoUOHolu3bjh06JD4/tzcXBHM+Pr64vDhw7h16xb69u0LW1tbTJs2rUDXotEpV2AGbOxKFfUlUAEwoCEiMpSTdaPQXis9tJ/Jzm0T/DUyMzMNttnb24v2JNzd3TFz5kz06NEDXl5eWL16tfhacf78eVSpUgVHjhxBw4YNRTanQ4cOuHnzJnx8fMQxixcvxtixY5GYmAg7O7snvm4OOREREclYQ2OiFhoaKrIpDzdl2+Mo2ZY1a9YgPT1dDD1FRkYiOzsbrVq10h9TuXJl+Pv7i4BGoTzWqFFDH8wogoKCkJqaiujo6AL9k3DIiYiISDYmnLYdEhKC4OBgg23/lp05ffq0CGCUehmlTmbDhg2oWrUqTp48KTIsxYsXNzheCV7i4uLE18rjw8FM3v68fQXBgIaIiIieanhJUalSJRG8pKSkYP369ejXrx/279+PwsaAhoiISDZmNG3bzs4OFSpUEF8HBAQgIiIC8+fPx3/+8x9kZWXh7t27BlkaZZaTUgSsUB6PHj1qcL68WVB5xzwp1tAQERHRc6PVakVRsRLcKLOVwsLC9PtiYmLENG1liEqhPCpDVgkJCfpjdu3aJaaAK8NWBcEMDRERkWzMZNp2SEgI2rZtKwp97927J2Y07du3Dzt27BDFxAMGDBD1OMrMJyVIGTZsmAhilBlOitatW4vApU+fPpgxY4aomxk/frxYu6Ygw14KBjRERET0VJTMirJujLJ+jBLAKIvsKcHMa6+9JvbPnTsXVlZWYkE9JWujzGBauHCh/vutra2xefNmDB48WAQ6zs7OogZnypQpBb4WrkNDT4Xr0BARFeE6NBPeMNm5naesgYxYQ0NERETS45ATERGRbEy4Do2sGNAQERHJxoymbZsLDjkRERGR9JihISIikoy53G3bnDBDQ0RERNJjhoaIiEg2rKExwgwNERERSY8ZGiIiItkwQ2OEGRoiIiKSHjM0REREsuHCekYY0BAREcmGQ05GOORERERE0rOogGbwoH64eCEcaamXcPjgJtSvVxuya9K4AX7ZsByxVyPFnV47dQqCuVt7/Ap6Lt2LRnO2iNZ35W84eCle7Et5kIXpO6PQ+evdaDBrE9os3InPd0XhXkZ2vue6+yALrRfsQO3pvyL1EceYIzV+FtXcLzX3jf2Sk06rM1mTlcUEND17dsKsmRPx2dQ5qN+gDU5FncXWLavg5eUBmTk7OyEq6iyGDR8HWfgUc8SHr1bF6rebiVa/jCdG/O93XExMRWJahmjBzatj/YAWmNKuDg5dTsDkbSfyPdekrSfwkpcrZKLWz6Ja+6XmvrFfpCYanU5nFuGYjV0pk55fidAjjp3C8BHjxXONRoOrlyOwYOEyzJi5AGqgZGi69eiPjRt3mPy17i3p9VzP13TeVoxsXg1da5Ux2rfz/A2M23QcRz5qDxsrK4NMz45zN/B+o0p4b81h/DaiHVwdbJ/pOoq9vwqmptbPolr7pea+sV/P/2dwYbn3YQeTnbvYF5shI4vI0Nja2qJu3ZoI23NAv02J48L2HETDhgFFem2WLlerw/az1/EgOxc1S5XI95i0zBy42NkYBDOXklLx9aEYTO1QV/ywkoVaP4tq7Zea+8Z+kdpYxCwnT0932NjYICE+yWB7QkIiKlcqX2TXZcn+SEhF3+9/Q1aOFo521pjT7WWU9zQeOrpzPxPfHIpBt9p/Z26ycnIR8mukyOj4uTnh+t37kIVaP4tq7Zea+8Z+SY43p3z2DM2DBw9w8OBBnD171mhfRkYGVq5c+dhzZGZmIjU11aCZycgXFZIXPVzwU/9X8X2/pni9TllM2HxcZF0elpaZjWHrwlHOsxgGNa6s3/7F/nMo61kM7au/UARXTkRE0gc0Fy5cQJUqVdC0aVPUqFEDzZo1w61bt/T7U1JS8M477zz2PKGhoXBzczNoOu09mEpSUjJycnLg7eNpsN3b2wtx8Ykme116NFtrK/iXcEFV3+KiQLiitytWH7us35+emY0P1h6Bs52NyN4ox+c5+mcidp2/gYDPN4r2/ppDYnvz+duw8MB5mDO1fhbV2i819439kpwyG8lUzRICmrFjx6J69epISEhATEwMihUrhkaNGiE2NrZALxoSEiKCn4ebxqoYTCU7OxvHj0ehRfPG+m1K3YXyPDw80mSvS09O+W9IGX7Ky8wM/ukIbK2sMK9HA9jbWBscO7vry1jbv7nI8ChtQtu/pmN+17sx3qhbFuZMrZ9FtfZLzX1jvyTHgObZamgOHz6M3bt3w9PTU7RNmzbhgw8+QJMmTbB37144Ozs/0Xns7e1Fe5ipCzvnzv8Gy5bOReTxKEREnMCHwwbC2dkRy1f8BNmnbVeo8Pcv8bIv+qNWrWpITr6Da9duwhx9se8sGpXzhq+rE+5n5WDb2es4FpuEhf8J1AczGdm5+G/HAKRn5oimKOFkD2srDV4oYfg5u3M/SzyW9Sj2zLOcCoNaP4tq7Zea+8Z+kZrYFLR+Rim2ejgIWbRoEYYOHSqGn1avXg1ztW7dRnh5umPShFHw9fXCqVPRaN+hNxISDAvHZFMvoBbCdq/XP589a5J4XLFyLQa8OxLmKPl+JsZvPo6k9Ey42NugoperCGYCy3oj4s8knL55RxzXcclug+/bMug1lCruBNmp9bOo1n6puW/sl7xYd/qM69C8/PLLGDZsGPr06WO0TwlqVq1aJQp8c3NzYW7r0JB5r0NjLgpjHRoiUqfCXIcm9X3TrQrvusT0a5kVeQ1N165d8eOPP+a776uvvsKbb77JqJGIiMjUWENjuSsF0/PFDA0RURFmaAa2Ntm5Xb/ZCRlZxMJ6REREqiJxJsVULOLWB0RERKRuzNAQERFJRscMjREGNERERLJhQGOEQ05EREQkPWZoiIiIZMObbRthhoaIiIikxwwNERGRZFgUbIwZGiIiIpIeMzRERESyYYbGCDM0REREJD1maIiIiGTDWU5GmKEhIiIi6TFDQ0REJBnOcjLGgIaIiEg2HHIywiEnIiIikh4zNERERJLhkJMxZmiIiIhIeszQEBERyYY1NEaYoSEiIiLpMaAhIiKSjE5rulYQoaGhqF+/PooVKwZvb2906dIFMTExBse8+uqr0Gg0Bm3QoEEGx8TGxqJ9+/ZwcnIS5xk9ejRycnIKdC0cciIiIqKnsn//fgwZMkQENUoA8sknn6B169Y4e/YsnJ2d9ccNHDgQU6ZM0T9XApc8ubm5Ipjx9fXF4cOHcevWLfTt2xe2traYNm3aE1+LRqfTmUWptI1dqaK+BCJ08guAWm28FVnUl0CkajlZNwrttW63b2ayc3ts2f/U35uYmCgyLEqg07RpU32Gpnbt2pg3b16+37Nt2zZ06NABN2/ehI+Pj9i2ePFijB07VpzPzs7uiV6bQ05ERESSMeWQU2ZmJlJTUw2asu1JpKSkiEd3d3eD7atWrYKnpyeqV6+OkJAQ3L9/X7/vyJEjqFGjhj6YUQQFBYnXjY6OfuJ/EwY0REREZFAX4+bmZtCUbY+j1WoxYsQINGrUSAQued566y388MMP2Lt3rwhmvv/+e/Tu3Vu/Py4uziCYUeQ9V/Y9KdbQEBERycaE07ZDQkIQHBxssM3e3v6x36fU0pw5cwYHDx402P7ee+/pv1YyMX5+fmjZsiUuXbqE8uXLP7frZoaGiIiIDIIXV1dXg/a4gGbo0KHYvHmzyMKULl36X49t0KCBeLx48aJ4VIqB4+PjDY7Je67se1IMaIiIiCRjLtO2dTqdCGY2bNiAPXv2oGzZso/9npMnT4pHJVOjCAwMxOnTp5GQkKA/ZteuXSKQqlq16hNfC4eciIiI6Kkow0yrV6/Gr7/+Ktaiyat5UepuHB0dxbCSsr9du3bw8PBAVFQURo4cKWZA1axZUxyrTPNWApc+ffpgxowZ4hzjx48X536Soa48DGiIiIgkU9BMiqksWrRIPzX7YcuWLcPbb78tplzv3r1bTNlOT0/HCy+8gO7du4uAJY+1tbUYrho8eLDI1ijr1/Tr189g3ZonwYCGiIiInsrjlrJTAhhlTZrHKVOmDLZu3YpnwYCGiIhIMuaSoTEnDGiIiIhko9MU9RWYHc5yIiIiIukxQ0NERCQZDjkZY4aGiIiIpMcMDRERkWR0WtbQ/BMzNERERCQ9ZmiIiIgkwxoaY8zQEBERkfSYoSEiIpKMjuvQGGFAQ0REJBkOORnjkBMRERFJjxkaIiIiyXDatjFmaIiIiEh6FhXQDB7UDxcvhCMt9RIOH9yE+vVqQy3U2jfZ+2VlZYU3P+qFRQe/wY8x67DwtyXo+eF/jI4rVaE0Qr4dh+9P/4jV59ZixsbZ8CzpCdnI/n5ZYt/YLznpdKZrsrKYgKZnz06YNXMiPps6B/UbtMGpqLPYumUVvLw8IDu19k0N/eo6uDuCerfFtxOW4MOWQ/D99BXo8n5XtHu7g/4YH39fTFs/Hdcv3cCEN8ZhZNCHWPfFT8jOzIZM1PB+WVrf2C9SE41OZx7xmI1dKZOeX4nQI46dwvAR48VzjUaDq5cjsGDhMsyYuQAyU2vfiqJfnfwCnuv5PvnuU9xNuouFY77Ubxu9+GNkZWRh/og54nnwl6OQk5OLL0bOhSltvBVp0vOr9XOo5r6xX89XTtYNFJY/67Yy2bnLHN8NGVlEhsbW1hZ169ZE2J4D+m1KHBe25yAaNny+v8AKm1r7ppZ+xUSeR81XasKvbEnx/MUqL6JKvao4sS9S/4M2oEU93LpyE5+unIRlkSsx/ZeZeLl1A8hELe+XJfWN/SK1KZJZTpmZmaI9TPnAKT/cTcHT0x02NjZIiE8y2J6QkIjKlcpDZmrtm1r69fPC9XB0ccSXexZCm6uFlbUVVs/8Ab/9sl/sd/N0g6OLkxiaWj3rBzEkVadZXYxZEiKGn87+Hg0ZqOX9sqS+sV9y4yyn5xDQnDt3DuHh4QgMDETlypVx/vx5zJ8/XwQovXv3RosWLR57jtDQUEyePNlgm8bKBRpr14JeDpFZe6VDYzTt0gxzP5yNaxdiUbZqWfSf+C6S45Ox7397oNH8lSQ9uut3bF66UXx99ewVVA6ojKBebaUJaIiocJlHsYjEQ07bt29H7dq1MWrUKNSpU0c8b9q0KS5evIg///wTrVu3xp49ex57npCQEKSkpBg0jVUxmEpSUjJycnLg7WM4a8Tb2wtx8YmQmVr7ppZ+9fvkbfy86H84tOkAYmP+xP4N+7Bp6UZ0+6CH2H/vTipysnNw/Y9rBt93/eJ1eJXygizU8n5ZUt/YL7LogGbKlCkYPXo0bt++jWXLluGtt97CwIEDsWvXLoSFhYl906dPf+x57O3t4erqatBMNdykyM7OxvHjUWjRvLF+m/J6yvPwcNMWSpqaWvumln7ZO9pDpzX8U0oMPVn99XlXgpmLUX+gZDnDoviSZUsi4UYCZKGW98uS+sZ+yT/kZKpmEUNO0dHRWLlypfj69ddfR58+fdCjx19/aSp69eolAh1zNHf+N1i2dC4ij0chIuIEPhw2EM7Ojli+4ifITq19U0O/InZHoMfQnki6mYjYC7EoV60cOr7bGXvW/j2L4NclGxD81WgxvHTmyGnUebUu6rV6GZ/+5xPIRA3vl6X1jf0ii66hycukKAuGOTg4wM3NTb+vWLFiYvjIHK1btxFenu6YNGEUfH29cOpUNNp36I2EBMPCMRmptW9q6Ne3E7/GWx/1wnufDYKrpxvuxCdj5+rtWDf/7x+sv+8Ix5Jxi8Qw1IDJA3Hz0g3MGDQd54+dg0zU8H5ZWt/YL3nxbtvPuA5NrVq18Pnnn6NNmzbi+ZkzZ0RhsFJRrjhw4AD69euHy5cvw9zWoSEqinVozImp16EhsnSFuQ7NpepBJjt3+TM7oPoMzeDBg5Gbm6t/Xr16dYP927Zte6JZTkRERPT0dNqivgLJA5pBgwb96/5p06Y96/UQERERybGwHhERET09LWtojDCgISIikgyLgi30Xk5ERESkbszQEBERSUbmBfBMhRkaIiIikh4zNERERJLhzSmNMUNDRERE0mOGhoiISDKsoTHGDA0RERFJjxkaIiIiyXBhPWMMaIiIiCTDhfWMcciJiIiIpMcMDRERkWQ4bdsYMzREREQkPWZoiIiIJMOiYGPM0BAREZH0mKEhIiKSDGc5GWOGhoiIiKTHDA0REZFkOMvJGDM0REREEhYFm6oVRGhoKOrXr49ixYrB29sbXbp0QUxMjMExGRkZGDJkCDw8PODi4oLu3bsjPj7e4JjY2Fi0b98eTk5O4jyjR49GTk5Oga6FAQ0RERE9lf3794tgJTw8HLt27UJ2djZat26N9PR0/TEjR47Epk2bsG7dOnH8zZs30a1bN/3+3NxcEcxkZWXh8OHDWLFiBZYvX44JEyYU6Fo0Op15JK5s7EoV9SUQqVpsvYpQozLHLkCNzOIHMxVITtaNQnutiFJdTXbu+jc2PPX3JiYmigyLErg0bdoUKSkp8PLywurVq9GjRw9xzPnz51GlShUcOXIEDRs2xLZt29ChQwcR6Pj4+IhjFi9ejLFjx4rz2dnZPdFrM0NDREREepmZmUhNTTVoyrYnoQQwCnd3d/EYGRkpsjatWrXSH1O5cmX4+/uLgEahPNaoUUMfzCiCgoLE60ZHR+NJMaAhIiKSjClraEJDQ+Hm5mbQlG2PvSatFiNGjECjRo1QvXp1sS0uLk5kWIoXL25wrBK8KPvyjnk4mMnbn7fvSXGWExEREemFhIQgODj47w0A7O3t8ThKLc2ZM2dw8OBBFAUGNERERJIxZY2Vvb39EwUwDxs6dCg2b96M3377DaVLl9Zv9/X1FcW+d+/eNcjSKLOclH15xxw9etTgfHmzoPKOeRIcciIiIqKnoswrUoKZDRs2YM+ePShbtqzB/oCAANja2iIsLEy/TZnWrUzTDgwMFM+Vx9OnTyMhIUF/jDJjytXVFVWrVn3ia2GGhoiISDLmcnPKIUOGiBlMv/76q1iLJq/mRam7cXR0FI8DBgwQQ1hKobASpAwbNkwEMcoMJ4UyzVsJXPr06YMZM2aIc4wfP16cuyCZIgY0REREkjGXezktWrRIPL766qsG25ctW4a3335bfD137lxYWVmJBfWU2VLKDKaFCxfqj7W2thbDVYMHDxaBjrOzM/r164cpU6YU6Fq4Dg2RheA6NHIxix/MZLbr0Bzy/WtNF1NoFLceMmKGhoiISDLaor4AM8SiYCIiIpIeMzRERESS0cE8amjMCTM0REREJD1maIiIiCSjZdW4EWZoiIiISHrM0BAREUlGyxoaI8zQEBERkfSYoSEiIpIMZzkZY0BDREQkGS6sZ4xDTkRERCQ9ZmiIiIgkwyEnY8zQEBERkfSYoSEiIpIMa2iMMUNDRERE0rOogGbwoH64eCEcaamXcPjgJtSvVxuya9K4AX7ZsByxVyORk3UDnToFQQ3U2i9ZP4sufd6C59JF8N21BT5bfkaJ6Z/B2v8Fg2PcxgTDe90P8Nu7HT5bNqDE51NhU+bvYxzbBaHk4b35NqsSxWGuxowZiiOHtyD5dgxuXD+F9euXomLF8lAL2T6Llt6vhzM0pmqyspiApmfPTpg1cyI+mzoH9Ru0wamos9i6ZRW8vDwgM2dnJ0RFncWw4eOgJmrtl6yfRbs6tZD+v1+Q9N4Q3B4+GhobG3jMmwGNg4P+mOyYC7j73xlIeLMfkkeOESWL7nNnAlZ//Zh5sHsv4jp0M2gZ4UeRefwktHfuwlw1bdIQixatQOMmHdG23ZuwtbHF1i2r4eTkCNnJ+Fm05H7Rv9PodLpnvsWVcgqN5tkqrm3sSsGUlAg94tgpDB8xXjxXrvfq5QgsWLgMM2YugBoomYxuPfpj48YdUBO19auoPoux9So+t3NZFXeD79ZfkPTBcGSdjMr3GJvy5eD9/VLE9+yF3Bs38z2Hz6/rcDd0Jh5s3/XU11Lm2AUUJk9Pd9y6eRrNW3TDwYO/m+x1CuPeg2r9uVhU/VJ+VhWWLT5vmuzc7eN/hMVmaOzt7XHu3DmYK1tbW9StWxNhew4YBGFhew6iYcOAIr02sixq+SxqnJ3FozY1Nf/9Dg5wat8GOTduIjc+Id9jHNu2hi4jEw/27IdM3NxcxeMdM84qWdJn0VL69U9ajemaRcxyCg4Oznd7bm4upk+fDg+Pv9J5c+bM+dfzZGZmiva8szz/9heVjY0NEuKTDLYnJCSiciX1jIWT+VPFZ1GjgduIocg8dRo5l68a7HLq1hmuH7wPKydHZP8Zi9sjRgM5OfmexqlDOzzYFQZkZUEWys+o2bMm49Cho4iOjoHMVPFZtKB+0XMOaObNm4datWqhePHiRsGIkqFxdnZ+oqAkNDQUkydPNtimsXKBxvqvv3yIyHy5fTQcNuXKImnQMKN9D3bsRubRY7D29IDLm6+jxGcTkTRoKJCVbXCcbfWqsC37Iu5OCYVMvvxiGqpVq4RXm3ct6kshC8e7bT9jQDNt2jR8/fXXmD17Nlq0aGGQ4lu+fDmqVq36ROcJCQkxyvaU8KgMU0lKSkZOTg68fTwNtnt7eyEuPtFkr0ukts+iW/CHcGgUKGpntImGfwErdOnpyFXa9RtIPnMWvjs2wrFZEzzYtcfgOKeO7ZF94Q9RSCyL+fOmol27VmjRshtu3LgF2cn+WbS0ftFzrqH5+OOP8dNPP2Hw4MEYNWoUsrMN/+oqSM2Nq6urQTPVcJNCuc7jx6PQonlj/Tbl9ZTn4eGRJntdIjV9FkUw06wxkoYFI/dW3OO/QflvWmm2toabHR3g2OJVpG/aCpmCmc6d26B10Ou4evUa1EDmz6Il9iu/onFTNYtZKbh+/fqIjIzEkCFDUK9ePaxatcqkwcjzMnf+N1i2dC4ij0chIuIEPhw2EM7Ojli+4ifIPr25QoWy+udlX/RHrVrVkJx8B9euGc8skYVa+yXrZ9Ft1Ag4vtYSyWPHQ3f/PqzcS4jt2rR0UQNjXdIPji2bi+Em7d27sPLyQrE+byoFc8g8YjgTyLFlC2hsrPFgx9PPbCrsYaY33uiCbt374969NPj4eIntKSn3kJGRAZnJ+Fm05H6RCW594OLighUrVmDNmjVo1aqVKAo2d+vWbYSXpzsmTRgFX18vnDoVjfYdeiMhwThtLpN6AbUQtnu9/vnsWZPE44qVazHg3ZGQlVr7Jetn0blbZ/HouXCewfY7U6fjwdYd0GVlwa5WDTj/pzusihWDNvkOMk9GIfH9YUZrzDh1bIsH+w5ApwRDEhg0qJ943BP2P4PtAwaMxMrv10JmMn4WLblfD5N5ATyzXYfm+vXrImOjBDZKUbC5rkNDZOme5zo05qSw16EpLDKn/i1VYa5D87PvWyY7d7e41bDIm1OWLl1aNCIiIiocWglKPQob77ZNREQkGWbwLPheTkRERKRezNAQERFJhkXBxpihISIiIukxQ0NERCQZmW8iaSrM0BAREZH0mKEhIiKSDG9OaYwZGiIiIpIeMzRERESS4To0xhjQEBERSYZFwcY45ERERETSY4aGiIhIMlxYzxgzNERERCQ9ZmiIiIgkw6JgY8zQEBERkfSYoSEiIpIMZzkZY4aGiIiIpMcMDRERkWQ4y8kYAxoiIiLJMKAxxiEnIiIikh4DGiIiIsnoNKZrBfHbb7+hY8eOKFmyJDQaDX755ReD/W+//bbY/nBr06aNwTHJycno1asXXF1dUbx4cQwYMABpaWkoKAY0RERE9FTS09NRq1YtLFiw4JHHKAHMrVu39O3HH3802K8EM9HR0di1axc2b94sgqT33nuvwNfCGhoiC+F/7ALU6O7QAKiRx8ITUCOtltUfz4Mp/xUzMzNFe5i9vb1o/9S2bVvR/o3yfb6+vvnuO3fuHLZv346IiAjUq1dPbPvyyy/Rrl07zJo1S2R+nhQzNERERKQXGhoKNzc3g6Zse1r79u2Dt7c3KlWqhMGDB+P27dv6fUeOHBHDTHnBjKJVq1awsrLC77//XqDXYYaGiIhIMqbM0ISEhCA4ONhgW37ZmSehDDd169YNZcuWxaVLl/DJJ5+IjI4SyFhbWyMuLk4EOw+zsbGBu7u72FcQDGiIiIjoscNLT+ONN97Qf12jRg3UrFkT5cuXF1mbli1b4nnikBMREZGEN6c0VTOlcuXKwdPTExcvXhTPldqahIQEg2NycnLEzKdH1d08CgMaIiIiCe/lZKpmStevXxc1NH5+fuJ5YGAg7t69i8jISP0xe/bsEcXjDRo0KNC5OeRERERET0VZLyYv26K4cuUKTp48KWpglDZ58mR0795dZFuUGpoxY8agQoUKCAoKEsdXqVJF1NkMHDgQixcvRnZ2NoYOHSqGqgoyw0nBDA0REZGERcGmagVx7Ngx1KlTRzSFUkysfD1hwgRR9BsVFYVOnTqhYsWKYsG8gIAAHDhwwKBGZ9WqVahcubKoqVGmazdu3Bhff/01CooZGiIiInoqr776KnS6R1fe7Nix47HnUDI5q1evxrNiQENERCQZLk9ojENOREREJD1maIiIiCRj6unVMmKGhoiIiKTHDA0REZFkTL1ejIwY0BAREUmGRcHGOORERERE0mOGhoiISDIsCjbGDA0RERFJjxkaIiIiyWiZozHCDA0RERFJjxkaIiIiyXCWkzFmaIiIiEh6zNAQERFJhhU0xhjQEBERSYZDThY+5DR4UD9cvBCOtNRLOHxwE+rXqw21UFvfmjRugF82LEfs1UjkZN1Ap05BUBO1vV+y9su2ZQ84jpgN52lr4DR5JRze+QQar1IGx2iKFYf9WyPhNGkFnEPXwjF4LqxrBhoc49B/HJw+XQrnz9fDadJycbzG1R3mbPz4kcjMuGbQok7thezGjBmKI4e3IPl2DG5cP4X165eiYsXyRX1ZVAgsJqDp2bMTZs2ciM+mzkH9Bm1wKuostm5ZBS8vD8hOjX1zdnZCVNRZDBs+DmqjxvdL1n5Zl6+O7ENb8GD+aGQsmQBYW8Px/cmAnb3+GCU4sfIuhYzvpuL+zGHIiToCh75jYFWqnP6Y3IunkbFyBu5PH4yM5dNh5eELh35jYe6io2PgX6auvjVv0Q2ya9qkIRYtWoHGTTqibbs3YWtji61bVsPJyRFqu5eTqZqsNDqdziyG4mzsDP8qet6UvxYjjp3C8BHjxXONRoOrlyOwYOEyzJi5ADJTc98USoamW4/+2LhxB9RAre9XUfXr7tCA53cyZ1e4fPYD7n8VAu3l6L82hf6EzPWLkBO57+/DPvsBmZtXIOf3XfmexrrayyLbkz6mO6DNfapL8Vh4AqbO0HTqGISXG7RBYdJqC3ewxNPTHbdunhbB2sGDv5v0tbKzbqCwTHixl8nOPeXqKsjIIjI0tra2qFu3JsL2HNBvU+K4sD0H0bDhc/xhWATU3Dc1Uuv7pZZ+aRyd//ri/j39ttyr52FTuwng5KJEaX99bWOH3Etn8j+Jkwts6jaD9ur5pw5mCkuFCmVx5fIxnD93EMuXf4EXXigJtXFzcxWPd+7chdoW1jNVs8ii4PT0dKxduxYXL16En58f3nzzTXh4PD69nJmZKdrDlB9+yl90porQbWxskBCfZLA9ISERlSvJPbaq5r6pkVrfL1X0S6OBfed3kXv5LLRxsfrNGStmwKHvaLhMXQ1dbg6QlYmMZdOgS7pl8O12HfrBtlF7aOwdRBD04NvPYM4ijp7AuwODceHCJfj5+mDcuBEIC/sf6tZthbS0dKiB8jtl9qzJOHToqBheI3UrUIamatWqSE5OFl9fu3YN1atXx8iRI7Fr1y5MnDhR7L9y5cpjzxMaGgo3NzeDptP+/RcREVFhs+82CFZ+/sj4fqbBdru2vUTm5sGi8XgwNxhZ+3+FQ78xsPIrY3Bc1t6fcX/OCDxYPEEZV4HDWyNgznbs3Ieff96CM2fOY9fu/ejcpR+Ku7miR48OUIsvv5iGatUqoVfvD6A2OhM2iwhozp8/j5ycHPF1SEgISpYsiT///BNHjx4VjzVr1sS4cY8v4lS+NyUlxaBprIrBVJKSksV1e/t4Gmz39vZCXHwiZKbmvqmRWt8v2ftl1+19WFethwcLx0OXclu/XePhC7smHZC55gvk/hEF7c2ryN65BrnXLsK2UTvDk6Tfgy7xJnIvnBRBkU3V+rAqUwmySElJxR9/XEH58i9CDebPm4p27VrhtdY9ceOGYTaN1Ompa2iOHDmCSZMmieyKwsXFBZMnT8bBgwcf+7329vZwdXU1aKYablJkZ2fj+PEotGjeWL9NeT3leXh4JGSm5r6pkVrfL5n7pQQzNjUaigyMLjneYJ/m/2c7Gc2dUApbNf/y4/P/f55pbGwh08zCcuXKIO5WAtQQzHTu3Aatg17H1avXoEZaEzaLqaHJCzwyMjJE3czDSpUqhcRE8/xrbO78b7Bs6VxEHo9CRMQJfDhsIJydHbF8xU+QnRr7pvxwVQoW85R90R+1alVDcvIdXLt2EzJT4/sla7/suw+CTd2mePDdf4HMB2LNGYUu474yZQXa+OvQJt6EQ88hyNz0HXTp92BTvSGsK9ZGxtK/amSs/CvC2v8lUXuje5AGKw8/MUylTbolamnM1fTQ8diydTdiY6/Dz88HEz4NRm5uLn5a+ytkH2Z6440u6Na9P+7dS4OPj5fYnpJyT/zeIvUqcEDTsmVLUfyXmpqKmJgYUUeTRxl2epKi4KKwbt1GeHm6Y9KEUfD19cKpU9Fo36E3EhIMixhlpMa+1QuohbDd6/XPZ8+aJB5XrFyLAe+OhMzU+H7J2q+8YSOnIaEG2zN+nIeciD1iltKDbybDvkM/OAz4FBo7B2hv30Lmj/OQe+7/M0/ZmbCuEQi7oDcBOwfoUu8g9/xxZO3+CVCKiM1UqVJ+WLniK3h4FEdiYjIOH45A02adxfChzAYN6ice94T9z2D7gAEjsfL7tUV0Vc+fzLORzGIdGmVI6WENGzZEUNDfK7iOHj0a169fx48//mh269AQkTo913VozIip16EpKoW9Dk1hKsx1aMa8+KbJzj3jasF/h0uXoVFmMv2bmTMNZwcQERERFQbenJKIiEgy6s1zPT2LWCmYiIiI1I0ZGiIiIsmwKNgYMzREREQkPWZoiIiIJMP8jDFmaIiIiEh6zNAQERFJhrOcjDGgISIikoyOg05GOORERERE0mOGhoiISDIccjLGDA0RERFJjxkaIiIiyXBhPWPM0BAREZH0mKEhIiKSDPMzxpihISIiIukxQ0NERCQZ1tAYY0BDREQkGU7bNsYhJyIiIpIeMzRERESS4a0PjDFDQ0RERE/lt99+Q8eOHVGyZEloNBr88ssvBvt1Oh0mTJgAPz8/ODo6olWrVvjjjz8MjklOTkavXr3g6uqK4sWLY8CAAUhLSyvwtTCgISIikrCGxlStINLT01GrVi0sWLAg3/0zZszAF198gcWLF+P333+Hs7MzgoKCkJGRoT9GCWaio6Oxa9cubN68WQRJ7733HgqKQ05ERET0VNq2bStafpTszLx58zB+/Hh07txZbFu5ciV8fHxEJueNN97AuXPnsH37dkRERKBevXrimC+//BLt2rXDrFmzRObnSTGgISKpeSw8ATWKqVwZavTS2bNFfQmqYMoamszMTNEeZm9vL1pBXLlyBXFxcWKYKY+bmxsaNGiAI0eOiIBGeVSGmfKCGYVyvJWVlcjodO3a9Ylfj0NOREREpBcaGioCj4ebsq2glGBGoWRkHqY8z9unPHp7exvst7Gxgbu7u/6YJ8UMDRERkWRMuQ5NSEgIgoODDbYVNDtTFBjQEBERSUarM92Qk/1TDC/lx9fXVzzGx8eLWU55lOe1a9fWH5OQkGDwfTk5OWLmU973PykOOREREdFzV7ZsWRGUhIWF6belpqaK2pjAwEDxXHm8e/cuIiMj9cfs2bMHWq1W1NoUBDM0REREkjGXZfXS0tJw8eJFg0LgkydPihoYf39/jBgxAlOnTsVLL70kApxPP/1UzFzq0qWLOL5KlSpo06YNBg4cKKZ2Z2dnY+jQoaJguCAznBQMaIiIiOipHDt2DM2bN9c/z6u96devH5YvX44xY8aItWqUdWWUTEzjxo3FNG0HBwf996xatUoEMS1bthSzm7p37y7WrikojU6ZKG4GbOxKFfUlEJGErK3UOXLOadvyyc66UWiv9VaZJ5/OXFCr/9wAGanzJwERERFZFA45ERERSYY3pzTGDA0RERFJjxkaIiIiyZhyYT1ZMaAhIiKSjJZDTkY45ERERETSY4aGiIhIMiwKNsYMDREREUmPGRoiIiLJsCjYGDM0REREJD1maIiIiCRjJnctMivM0BAREZH0mKEhIiKSDNehMcaAhoiISDIsCjbGISciIiKSnsUENE0aN8AvG5Yj9mokcrJuoFOnIKjJ4EH9cPFCONJSL+HwwU2oX6821ID9kosa+zV+/EhkZlwzaFGn9sKcufV/A36rvoL/oV/xwp618J47CTZlSuv3W7kWg/vYISj1y3fwD9+M0ttWwX3MB9C4OOmPcenUGi+e3JVvsypRHObq/ff64njkLtxOOi/agd82IiioOdS4sJ6p/icriwlonJ2dEBV1FsOGj4Pa9OzZCbNmTsRnU+egfoM2OBV1Flu3rIKXlwdkxn7JRa39UkRHx8C/TF19a96iG8yZQ0BN3PtpI271/RBxgz4GbGzgu2g6NA4OYr+1l4doyXO+xs0eA5E0YSYcG9WH58SP9OdI37EP11q+btAeHIpAxrFT0N65C3N1/cYtfDIuFA0atkXDwHbYu+8Qfv7fd6hatWJRXxqZmEZnJnO/bOxKFdprKRmabj36Y+PGHVAD5S/hiGOnMHzEePFco9Hg6uUILFi4DDNmLoCs2C+5FFW/rK2sTJ6h6dQxCC83aIPCFFO58nM7l1UJN/jvXY9b/YORefx0vsc4vdYUXv8diz8DOwK52nzP8cLOH5E0aQ7St+x+6mt56exZFLb4uDP4+OOpWLZ8jUlfJzvrBgpLO/92Jjv31titkJHFZGjUytbWFnXr1kTYngP6bUqMGrbnIBo2DICs2C+5qLVfeSpUKIsrl4/h/LmDWL78C7zwQknIxMrFWTxqU+796zHatPv5BjMKlw6vQZeRifu7f4MsrKys8PrrnUSGPvz3yKK+HDIxznKSnKenO2xsbJAQn2SwPSEhEZUrlYes2C+5qLVfioijJ/DuwGBcuHAJfr4+GDduBMLC/oe6dVshLS0dZk+jgfvowcg4cQbZl67me4hVcVcUH9gL935+9F/mLl3aIG3bHugys2DuqlevLGpnHBzsxXvUo+e7OHfuD6iJmQyuyJuhOX78OK5cuaJ//v3336NRo0Z44YUX0LhxY6xZ82TpvMzMTKSmpho0vjlEZI527NyHn3/egjNnzmPX7v3o3KUfiru5okePDpCBe8gw2FV4EYlj/5vvfo2zE3y+nIqsy3/i7uKV+R5jX7MK7MqXQdqG7ZBBTMwl1KvfGo0adcCSr1fiu6XzUKXKS0V9WWROAc0777yDS5cuia+//fZbvP/++6hXrx7GjRuH+vXrY+DAgfjuu+8ee57Q0FC4ubkZNJ320alQerSkpGTk5OTA28fTYLu3txfi4hMhK/ZLLmrtV35SUlLxxx9XUL78izB37h8PhVPTBoh7dzRyEwyzZwqNkyN8Fk6DNv0BEoMnATm5+Z7HpWtbZJ6/iCxJshzZ2dm4dOkqjp84jfHjp/81IWTou1ATrQmbRQQ0f/zxB1566a8od+HChZg/f75ogwYNwty5c7FkyRLMnj37secJCQlBSkqKQdNYFXv6Xlgw5T/c48ej0KJ5Y/02pRhTeR4eLu+YMfslF7X2Kz9KPUa5cmUQdysBZh/MtGiEuPfGIOdmXP6ZmUXTgewcJIyYAF1Wdr7n0Tg6wLl1M2myM4+qpbG3t4OacNr2M9bQODk5ISkpCWXKlMGNGzfw8ssvG+xv0KCBwZDUo9jb24v2MOWHn6l/CCmFfXnKvuiPWrWqITn5Dq5duwmZzZ3/DZYtnYvI41GIiDiBD4cNhLOzI5av+AkyY7/kotZ+TQ8djy1bdyM29jr8/Hww4dNg5Obm4qe1v8JcuX8yDC5tWyB+xETo0u/D2qOE2K5NSxc1MEow89c0bnskjJsOK2cnQGkAcu+kANq//053DnoVsLZG+tann9lUmKZO/Rjbt+/FtWs3UKyYC954owuaNQtEu/ZvFfWlkTkFNG3btsWiRYvEcFOzZs2wfv161KpVS79/7dq1qFChAsxRvYBaCNu9Xv989qxJ4nHFyrUY8O5IyGzduo3w8nTHpAmj4OvrhVOnotG+Q28k5JNilgn7JRe19qtUKT+sXPEVPDyKIzExGYcPR6Bps85imM1cub7eSTz6LTXMmCvrzaRt3An7KhVEXYyi9GbDupnr7Xoj52a8/rlL1za4v+cgtPckKIBWhjm9PLHsu/nw8/NGSso9nD59TgQzYWF/z8BTA97L6RnXobl586YoAvb39xe1M0pwExAQgCpVqiAmJgbh4eHYsGED2rVrZ9br0BCReph6HZqi8jzXoTEnRbEOTWEpzHVoWr1gutXud1+Tc422Av0kKFmyJE6cOIHAwEBs375dzEw6evQodu7cidKlS+PQoUNPFcwQERHRk1N+/5qqycoiVwomIvVghkYuzNA8Hy1LtzbZucOu74SMuLAeERGRZFhDY0ydf9oQERGRRWGGhoiISDIyrxdjKgxoiIiIJKM1j/JXs8IhJyIiIpIeMzRERESSYX7GGDM0REREJD1maIiIiCTDadvGmKEhIiIi6TFDQ0REJBlmaIwxQ0NERETSY4aGiIhIMmZyG0azwgwNERERSY8ZGiIiIsmwhsYYAxoiIiLJ8F5OxjjkRERERNJjhoaIiEgyLAo2xgwNERERSY8BDRERkYRFwaZqBTFp0iRoNBqDVrlyZf3+jIwMDBkyBB4eHnBxcUH37t0RHx8PU2BAQ0RERE+tWrVquHXrlr4dPHhQv2/kyJHYtGkT1q1bh/379+PmzZvo1q0bTIE1NERERJIxpxoaGxsb+Pr6Gm1PSUnB0qVLsXr1arRo0UJsW7ZsGapUqYLw8HA0bNjwuV4HMzRERESkl5mZidTUVIOmbHuUP/74AyVLlkS5cuXQq1cvxMbGiu2RkZHIzs5Gq1at9Mcqw1H+/v44cuQIVJuh0UCdzCeGJlKnXK0WalTh7FmoUXxQhaK+BFUw5cJ6oaGhmDx5ssG2iRMninqZf2rQoAGWL1+OSpUqieEm5fuaNGmCM2fOIC4uDnZ2dihevLjB9/j4+Ih9qg1oiIiIqOgX1gsJCUFwcLDBNnt7+3yPbdu2rf7rmjVrigCnTJkyWLt2LRwdHVGYOOREREREBsGLq6urQXtUQPNPSjamYsWKuHjxoqirycrKwt27dw2OUWY55Vdz86wY0BAREUlGq9OZrD2LtLQ0XLp0CX5+fggICICtrS3CwsL0+2NiYkSNTWBgIJ43DjkRERHRUxk1ahQ6duwohpmUKdlKrY21tTXefPNNuLm5YcCAAWL4yt3dXWR6hg0bJoKZ5z3DScGAhoiISDLmcnPK69evi+Dl9u3b8PLyQuPGjcWUbOVrxdy5c2FlZSUW1FNmSgUFBWHhwoUmuRaNzkwms9valYIamcU/LhGRmVDzLCePTfsL7bWq+TQw2bmj43+HjJihISIiksyz1rqoEYuCiYiISHrM0BAREUnGXGpozAkDGiIiIslwyMkYh5yIiIhIeszQEBERSYZDTsaYoSEiIiLpMUNDREQkGdbQGGOGhoiIiKTHDA0REZFkWENjjBkaIiIikh4zNERERJLR6bRFfQlmhwENERGRZLQccjLCISciIiKSHjM0REREktFx2rYRZmiIiIhIehYR0IwZMxRHDm9B8u0Y3Lh+CuvXL0XFiuWhJoMH9cPFC+FIS72Ewwc3oX692lAD9ksuau2XGvvWpHED/LJhOWKvRiIn6wY6dQqCuXPo0Qtuc5bA/adtKPH9Lyg2biqsSr1gcIzrtHnw2LTfoDl/EKzfrynmimKTZqDE8v/B/eddKP7dOji/PxwaRyfIVkNjqiYriwhomjZpiEWLVqBxk45o2+5N2NrYYuuW1XBycoQa9OzZCbNmTsRnU+egfoM2OBV1Flu3rIKXlwdkxn7JRa39UmvfnJ2dEBV1FsOGj4MsbKvXQsaWDUgZPRipn34EWNvAdcoswN7B4LiM7ZuQ3Kervt1ftvjvnVotsn4/hNSpn+Du+72RNi8UtrUD4Dzko8LvED1XGp2ZDMTZ2pUqtNfy9HTHrZun0bxFNxw8+LtJX6sw/nGVvxYjjp3C8BHjxXONRoOrlyOwYOEyzJi5ALJiv+Si1n6pvW8KJUPTrUd/bNy4w+SvFR9U4bmdS+PqBvdVG5Hy8TDkREfpMzQ5ly/i/rdfPfF5HDp2h0PXN3C3f89nuh4lG1RYSpWoZrJz37gTDRlZRIbmn9zcXMXjnTt3ITtbW1vUrVsTYXsO6LcpMWrYnoNo2DAAsmK/5KLWfqm9b7LTOLuIR929ewbb7V99DSVW/Qq3r5bBqe9AwN7+0edw94BdYBPknDlp8uslFc5yyszMFO1hyg8I5a8eU1NeY/asyTh06Ciio2MgOyXbZGNjg4T4JIPtCQmJqFxJ3joh9ksuau2X2vsmNY0GzgOHIvtsFHJjr+g3Z+4PgzYhDtrk27B+sRyc3n4fVqX8kRb6qcG3u4yaALuGjaCxdxBDUGlfzoRMeHPKZ8zQDBs2DAcO/P1XytMKDQ2Fm5ubQdNqDSNsU/nyi2moVq0SevX+oFBej4iInj/nQSNh7V8WaTOmGGzP3LEJ2ScikPvnZWTt3420udNg/0pTWPmWNDgu/duvcHfEQKR+FgIrv5JwfncIZLuXk6n+ZxEBzYIFC/Dqq6+iYsWK+PzzzxEXF/dULxoSEoKUlBSDZmVVDKY2f95UtGvXCq+17okbN25BDZKSkpGTkwNvH0+D7d7eXoiLT4Ss2C+5qLVfau+brJRZSbb1A5E6bgS0t//9PciJOScerf0M6zR1d5OhvR6L7KOHkb5gNhzadYGmhLtJr5vMrIZm586daNeuHWbNmgV/f3907twZmzdvhlb75PeVsLe3h6urq0Ez9XCTEsx07twGrYNex9Wr16AW2dnZOH48Ci2aN9ZvU/4tlefh4ZGQFfslF7X2S+19kzWYUWpeRDAT//g/qm3K/VWErL1z+9EH/f/vH42tHWShlGmYqllMDU2NGjXQsmVLzJw5Exs2bMB3332HLl26wMfHB2+//TbeeecdVKjw/KrYn9cw0xtvdEG37v1x714afHy8xPaUlHvIyMiA7ObO/wbLls5F5PEoREScwIfDBsLZ2RHLV/wEmbFfclFrv9TaN2XadoUKZfXPy77oj1q1qiE5+Q6uXbsJc+Q8eCTsmrbEvf+Og+7BA2iK/5VR0d1PA7KyxLCSfbNWyDoWDt29VFFD4/zuUGSfOYncq5fFsbYBDWBV3B05f5yHLuMBrP1fhNM7g0UtjlJ7QxYybdvKykoMM3l7extsj42NFYHN8uXLce3aNeTm5prVtO3srBv5bh8wYCRWfr8WplRYse4Hg9/GR8GD4evrhVOnojFi5AQcjTgB2bFfclFrv9TYt2ZNAxG2e73R9hUr12LAuyPNctr2o6ZFK2vJZIZth5WnF1w+Gi9qazQODtAmJSLryAE8+GkldA/ui2NtatSBU593Yf1CGZGR0SYlIOvIb3iwfjV06WlPfW3/dn2m4OVWyWTnTkyJsdyAJo9yqt27d+O1114z63VoCpO8yTsiIvNeh8bcMKApWgUacipTpgysra0fuV8ZV36aYIaIiIienMy1LmYR0Fy58vdcfyIiIiKLXliPiIiInh4X1jPGgIaIiEgyHHIyZpH3ciIiIiJ1YYaGiIhIMlrOoTXCDA0RERFJjxkaIiIiybCGxhgzNERERCQ9ZmiIiIgkw2nbxpihISIiIukxQ0NERCQZHWc5GWFAQ0REJBkOORnjkBMRERFJjxkaIiIiyXDatjFmaIiIiEh6zNAQERFJhkXBxpihISIiIukxQ0NERCQZ1tAYY4aGiIiIpMeAhoiISMIMjana01iwYAFefPFFODg4oEGDBjh69CgKGwMaIiIiyehM2Arqp59+QnBwMCZOnIjjx4+jVq1aCAoKQkJCAgoTAxoiIiLSy8zMRGpqqkFTtj3KnDlzMHDgQLzzzjuoWrUqFi9eDCcnJ3z33XcoVDoLk5GRoZs4caJ4VBP2Sz5q7Rv7JRe19kvtfTOliRMnGiVulG35yczM1FlbW+s2bNhgsL1v3766Tp066QqTRvk/WBAl0nRzc0NKSgpcXV2hFuyXfNTaN/ZLLmrtl9r7ZkqZmZlGGRl7e3vR/unmzZsoVaoUDh8+jMDAQP32MWPGYP/+/fj9999RWDhtm4iIiB4bvJg71tAQERHRU/H09IS1tTXi4+MNtivPfX19UZgY0BAREdFTsbOzQ0BAAMLCwvTbtFqteP7wEFRhsLghJyWNpkwtkzGd9m/YL/motW/sl1zU2i+1982cBAcHo1+/fqhXrx5efvllzJs3D+np6WLWU2GyuKJgIiIier6++uorzJw5E3Fxcahduza++OILscBeYWJAQ0RERNJjDQ0RERFJjwENERERSY8BDREREUmPAQ0RERFJz6ICGnO4vfnz9ttvv6Fjx44oWbIkNBoNfvnlF6hBaGgo6tevj2LFisHb2xtdunRBTEwMZLdo0SLUrFlTLMOuNGWdhm3btkFtpk+fLj6PI0aMgOwmTZok+vJwq1y5MtTgxo0b6N27Nzw8PODo6IgaNWrg2LFjkJnyM/6f75fShgwZUtSXRiZmMQGNudze/HlT5vorfVGCNTVR7gGi/AAKDw/Hrl27kJ2djdatW4v+yqx06dLil31kZKT4xdGiRQt07twZ0dHRUIuIiAgsWbJEBG5qUa1aNdy6dUvfDh48CNnduXMHjRo1gq2trQiqz549i9mzZ6NEiRKQ/fP38Hul/PxQ9OzZs6gvjUxNZyFefvll3ZAhQ/TPc3NzdSVLltSFhobq1EJ5O/95x1O1SEhIEP3bv3+/Tm1KlCih+/bbb3VqcO/ePd1LL72k27Vrl65Zs2a64cOH62Sn3GW4Vq1aOrUZO3asrnHjxjq1Uz6D5cuX12m12qK+FDIxi8jQZGVlib+IW7Vqpd9mZWUlnh85cqRIr42ejHK3XIW7uzvUIjc3F2vWrBFZp8JeItxUlKxa+/btDf5bU4M//vhDDOuWK1cOvXr1QmxsLGS3ceNGsbKrkrlQhnXr1KmDb775Bmr72f/DDz+gf//+YtiJ1M0iApqkpCTxy8PHx8dgu/JcWdWQzJtyXxClFkNJj1evXh2yO336NFxcXMRy7IMGDcKGDRtQtWpVyE4JzpThXKX+SU2Uervly5dj+/btogbqypUraNKkCe7duweZXb58WfTnpZdewo4dOzB48GB8+OGHWLFiBdRCqSm8e/cu3n777aK+FCoEFncvJ5Lzr/4zZ86oom5BUalSJZw8eVJkndavXy/ugaLUDMkc1Fy7dg3Dhw8X9QpK0b2atG3bVv+1UhekBDhlypTB2rVrMWDAAMj8h4KSoZk2bZp4rmRolP/OFi9eLD6TarB06VLx/inZNVI/i8jQmNPtzalghg4dis2bN2Pv3r2ioFYtd6etUKGCuEOtks1Qirrnz58PmSlDukqBfd26dWFjYyOaEqQp93NRvlYypGpRvHhxVKxYERcvXoTM/Pz8jILoKlWqqGI4TfHnn39i9+7dePfdd4v6UqiQWERAY063N6cno9Q4K8GMMhyzZ88elC1bFmqlfBYzMzMhs5YtW4qhNCXzlNeUv/6VehPla+UPCrVIS0vDpUuXREAgM2UI959LIVy4cEFkn9Rg2bJlojZIqekiy2AxQ07mcntzU/xwffgvRWV8X/kFohTP+vv7Q+ZhptWrV+PXX38Va9Hk1Tq5ubmJ9TJkFRISIlLgynuj1GAofdy3b5+oYZCZ8h79s77J2dlZrG8ie93TqFGjxFpPyi/6mzdviqUflADtzTffhMxGjhyJV155RQw5vf7662Jdrq+//lo0NfyRoAQ0ys98JUNIFkJnQb788kudv7+/zs7OTkzjDg8P18lu7969YjrzP1u/fv10MsuvT0pbtmyZTmb9+/fXlSlTRnwGvby8dC1bttTt3LlTp0Zqmbb9n//8R+fn5yfes1KlSonnFy9e1KnBpk2bdNWrV9fZ29vrKleurPv66691arBjxw7x8yImJqaoL4UKkUb5v6IOqoiIiIiehUXU0BAREZG6MaAhIiIi6TGgISIiIukxoCEiIiLpMaAhIiIi6TGgISIiIukxoCEiIiLpMaAhIiIi6TGgISIiIukxoCEiIiLpMaAhIiIiyO7/AD2mfm5JKd3uAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00       404\n",
            "           1       0.99      1.00      1.00       380\n",
            "           2       0.99      1.00      0.99       325\n",
            "           3       1.00      1.00      1.00        86\n",
            "           4       1.00      0.98      0.99       241\n",
            "           5       0.98      0.97      0.97       291\n",
            "           6       0.97      0.96      0.97       236\n",
            "           7       0.98      0.99      0.98       256\n",
            "\n",
            "    accuracy                           0.99      2219\n",
            "   macro avg       0.99      0.99      0.99      2219\n",
            "weighted avg       0.99      0.99      0.99      2219\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNP6aqzc9hE5"
      },
      "source": [
        "# Convert to model for Tensorflow-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "ODjnYyld9hE6"
      },
      "outputs": [],
      "source": [
        "# Save as a model dedicated to inference\n",
        "model.save(model_save_path, include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRfuK8Y59hE6",
        "outputId": "a4ca585c-b5d5-4244-8291-8674063209bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/h8/7g6ps5r13vn_sdc7z1081w480000gr/T/tmpm82p01qs/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/h8/7g6ps5r13vn_sdc7z1081w480000gr/T/tmpm82p01qs/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/var/folders/h8/7g6ps5r13vn_sdc7z1081w480000gr/T/tmpm82p01qs'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 42), dtype=tf.float32, name='input_layer_11')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 8), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  15456965392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  15456960784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  15456966928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  15456960976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  15456968080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  15456961168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  15456961360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  15456972688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  14221047184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  14221047952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  15456962128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  15456960592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  14221046608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  14221040464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  14221046032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  14221045072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  14221045456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  14221044304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  14221045840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  14221047760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1753105705.258159 34673502 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1753105705.258327 34673502 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "40112"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Transform model (quantization)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Enable TensorFlow ops and disable experimental tensor list lowering\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS\n",
        "]\n",
        "\n",
        "converter._experimental_lower_tensor_list_ops = False\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHBPBXdx9hE6"
      },
      "source": [
        "# Inference test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "mGAzLocO9hE7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/marcolee/Desktop/pathpulse/projects/venv/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
            "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
            "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
            "    for details.\n",
            "    \n",
            "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "oQuDK8YS9hE7"
      },
      "outputs": [],
      "source": [
        "# Get I / O tensor\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "2_ixAf_l9hE7"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4FoAnuc9hE7",
        "outputId": "91f18257-8d8b-4ef3-c558-e9b5f94fabbf",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 479 μs, sys: 1.12 ms, total: 1.59 ms\n",
            "Wall time: 1.08 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Inference implementation\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vONjp19J9hE8",
        "outputId": "77205e24-fd00-42c4-f7b6-e06e527c2cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.6578599e-07 3.5660830e-06 4.7386457e-06 1.2274836e-06 1.2485729e-05\n",
            " 9.9823511e-01 1.7393538e-03 3.4246314e-06]\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "keypoint_classification_EN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
